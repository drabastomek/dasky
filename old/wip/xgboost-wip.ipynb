{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Python with Azure ML and Dask\n",
    "\n",
    "![Describe gif](media/describe.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "\n",
    "This notebook assumes you are using an Azure ML Compute Instance with the default kernel `azureml_py36`. This contains many unneccesary packages. If you want to avoid a long image build time, you may want to create a new conda environment with the minimal packages needed for your scenario. \n",
    "\n",
    "It is important that the local environment matches the remote environment to avoid mismatch issues when submitting commands to the remote cluster. To help with this, we will use Azure ML Environments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade dask[complete] dask-ml[complete] tpot  adlfs lz4 distributed fastparquet pyarrow azureml-sdk[notebooks] lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uninstall some bugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall azureml-samples azureml-mlflow -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important! \n",
    "\n",
    "Restart your kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for a strange bug with compute instances \n",
    "import os\n",
    "\n",
    "os.system('sudo cp /etc/nginx/nginx.conf setup/temp.conf') # stupid\n",
    "\n",
    "nginx = ''\n",
    "\n",
    "with open('setup/temp.conf') as f:\n",
    "    for line in f.readlines():\n",
    "        if 'websocket/|/ws/' in line:\n",
    "            nginx += line.replace('websocket/|/ws/', 'websocket/|/ws')\n",
    "        else:\n",
    "            nginx += line\n",
    "       \n",
    "with open('setup/temp2.conf', 'w') as f:\n",
    "    f.write(nginx)\n",
    "    \n",
    "os.system('sudo mv setup/temp2.conf /etc/nginx/nginx.conf')\n",
    "os.system('sudo service nginx restart')\n",
    "os.system('rm setup/temp.conf');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Import all packages used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint hyperdrive = azureml.train.hyperdrive:HyperDriveRun._from_run_dto with exception cannot import name '_DistributedTraining'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import dask\n",
    "import glob\n",
    "import time\n",
    "import fsspec\n",
    "import socket\n",
    "import matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from dask.distributed import Client\n",
    "from IPython.core.display import HTML\n",
    "from dask_ml.xgboost import XGBRegressor\n",
    "\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.estimator import Estimator\n",
    "from azureml.core.runconfig import MpiConfiguration\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "from azureml.core import Workspace, Experiment, Dataset, Environment\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure ML setup\n",
    "\n",
    "Get the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workspace.create(name='ncus-azureml', subscription_id='6560575d-fa06-4e7d-95fb-f962e74efd7a', resource_group='copeters-rg')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws = Workspace.from_config()\n",
    "ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data access setup\n",
    "\n",
    "This is for a ADLS gen2 account I have provisioned with data. It should be read-able publicly.\n",
    "\n",
    "You **should not** keep storage account keys in plain text format, and you definitely should not upload them to github in a public repo. \n",
    "\n",
    "Use the keyvault with the workspace through the Python SDK or Azure Portal to set the account name and key for your storage account, and use the keyvault to retrieve the secrets and pass them through. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyvault = ws.get_default_keyvault()\n",
    "keyvault.set_secret('daskdataaccount', 'data4dask')\n",
    "keyvault.set_secret('daskdatakey', 'mupxHTCWrYQC252cFAWCAm7lSlMPTCt5J3j7FCXIlXW/k3OIdLrWssVnMGKVX6N96XoIlw9O8PkQya3cNB9xKw==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "STORAGE_OPTIONS = {\n",
    "    'account_name': keyvault.get_secret('daskdataaccount'), \n",
    "    'account_key' : keyvault.get_secret('daskdatakey')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create environment \n",
    "\n",
    "Create the environment to be used on the remote cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dask-ml', '1')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env_name = 'dask-ml'\n",
    "\n",
    "if env_name not in ws.environments:\n",
    "    env = Environment.from_existing_conda_environment(env_name, 'azureml_py36')\n",
    "    env.python.conda_dependencies.add_pip_package('mpi4py') # needed for remote cluster\n",
    "    env = env.register(ws)\n",
    "else:\n",
    "    env = ws.environments[env_name]\n",
    "    \n",
    "env.name, env.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create VM pool\n",
    "\n",
    "Create Azure ML VM pool for creating remote dask cluster(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmlCompute(workspace=Workspace.create(name='ncus-azureml', subscription_id='6560575d-fa06-4e7d-95fb-f962e74efd7a', resource_group='copeters-rg'), name=raspberrypis, id=/subscriptions/6560575d-fa06-4e7d-95fb-f962e74efd7a/resourceGroups/copeters-rg/providers/Microsoft.MachineLearningServices/workspaces/ncus-azureml/computes/raspberrypis, type=AmlCompute, provisioning_state=Succeeded, location=northcentralus, tags=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_name = 'raspberrypis'\n",
    "\n",
    "if pool_name not in ws.compute_targets:\n",
    "    # create config for Azure ML cluster\n",
    "    # change properties as needed\n",
    "    config = AmlCompute.provisioning_configuration(\n",
    "             vm_size                       = 'STANDARD_D13_V2',   # 8 vCPUS 56 GB RAM 112 GB disk \n",
    "             max_nodes                     = 100,\n",
    "             vnet_resourcegroup_name       = ws.resource_group,   # replace if needed\n",
    "             vnet_name                     = 'dialup-network',    # replace if needed\n",
    "             subnet_name                   = 'default',           # replace if needed\n",
    "             idle_seconds_before_scaledown = 300\n",
    "    )\n",
    "    ct = ComputeTarget.create(ws, pool_name, config)\n",
    "    ct.wait_for_completion(show_output=True)    \n",
    "else:\n",
    "    ct = ws.compute_targets[pool_name]\n",
    "    \n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Startup cluster\n",
    "\n",
    "Start the run now. The first time, this will take "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>dask-xgboost</td><td>dask-xgboost_1578872294_ecf303d5</td><td>azureml.scriptrun</td><td>Running</td><td><a href=\"https://ml.azure.com/experiments/dask-xgboost/runs/dask-xgboost_1578872294_ecf303d5?wsid=/subscriptions/6560575d-fa06-4e7d-95fb-f962e74efd7a/resourcegroups/copeters-rg/workspaces/ncus-azureml\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: dask-xgboost,\n",
       "Id: dask-xgboost_1578872294_ecf303d5,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Running)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name   = 'dask-xgboost'\n",
    "\n",
    "est = Estimator('../setup', \n",
    "                compute_target          = ct, \n",
    "                entry_script            = 'start.py',          # sets up Dask cluster\n",
    "                environment_definition  = env,                 # use same env as local\n",
    "                node_count              = 40,                  # 20 nodes -> 160 vCPUs, 1 TB RAM\n",
    "                distributed_training    = MpiConfiguration()\n",
    "               )\n",
    "\n",
    "#run = next(ws.experiments[exp_name].get_runs()) # use this to get existing run (if kernel restarted, etc)\n",
    "run = Experiment(ws, exp_name).submit(est)\n",
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale up with Dask and Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b41189ca194b4e82adc9b33b0119f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/dask-xgboost/runs/dask-xgboost_1578872294_ecf303d5?wsid=/subscriptions/6560575d-fa06-4e7d-95fb-f962e74efd7a/resourcegroups/copeters-rg/workspaces/ncus-azureml\", \"run_id\": \"dask-xgboost_1578872294_ecf303d5\", \"run_properties\": {\"run_id\": \"dask-xgboost_1578872294_ecf303d5\", \"created_utc\": \"2020-01-12T23:38:16.416625Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"842f7649-fb33-4b19-a9ba-37de3649eb2d\", \"azureml.git.repository_uri\": \"http://github.com/lostmygithubaccount/dasky.git\", \"mlflow.source.git.repoURL\": \"http://github.com/lostmygithubaccount/dasky.git\", \"azureml.git.branch\": \"master\", \"mlflow.source.git.branch\": \"master\", \"azureml.git.commit\": \"fa78b0f249d7d858324e906e85547cb07c5fc163\", \"mlflow.source.git.commit\": \"fa78b0f249d7d858324e906e85547cb07c5fc163\", \"azureml.git.dirty\": \"True\", \"AzureML.DerivedImageName\": \"azureml/azureml_9cb397f307ffffb51d62ded43f721583\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":40}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_08ba4fc2564c12e743f9c7ee0d5ee30f59f2b026d795f29cd0148f1b1d70780f_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_08ba4fc2564c12e743f9c7ee0d5ee30f59f2b026d795f29cd0148f1b1d70780f_d.txt?sv=2019-02-02&sr=b&sig=8VgOApjB7NkdZMpvQvsmq2TBlZA8hza0B7XKoHCXkPc%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_1659e1dace2241c029d647263ff2a51ede9d9c003bdf45673109c8c81b00ee24_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_1659e1dace2241c029d647263ff2a51ede9d9c003bdf45673109c8c81b00ee24_d.txt?sv=2019-02-02&sr=b&sig=PpJ%2B5XMFm5HA3bwbchm9V9cg%2FcwVrV6sEutfdgjZLtI%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_1e5482d9b0b6288f35c5dfbb022cf63e77b87ccf7b918bc3fd080ae288818cd7_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_1e5482d9b0b6288f35c5dfbb022cf63e77b87ccf7b918bc3fd080ae288818cd7_d.txt?sv=2019-02-02&sr=b&sig=g9li0F7bCtPIENk4%2Fta8Q81Z%2BTVTTE735pToPE0kCiA%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_2c3a415254f21fd09c8ce8aebfa60ff7e9ec296ea21506293f4bf0564ad586a0_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_2c3a415254f21fd09c8ce8aebfa60ff7e9ec296ea21506293f4bf0564ad586a0_d.txt?sv=2019-02-02&sr=b&sig=16JpjIbe%2F6%2FmVqYh9ecn8fJPGbx7vnWbKENn5z6sDvY%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_3c776006b52538e1bbf82873aec75313d85170583b552aad04f85de9469612c1_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_3c776006b52538e1bbf82873aec75313d85170583b552aad04f85de9469612c1_d.txt?sv=2019-02-02&sr=b&sig=vdjmXj5NOul2NfyBc1MTDXPFDe%2B2L88Zd7rs3srcXNE%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_44f2233f2aafccc8182330cb3e3ba7ec642ef8e8e55074ed484cde6b1ae103ab_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_44f2233f2aafccc8182330cb3e3ba7ec642ef8e8e55074ed484cde6b1ae103ab_d.txt?sv=2019-02-02&sr=b&sig=l54ShmzmOQu3CLsGMa5gamnpSPQJG0pYeeCyPkD4IIE%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_45923ec3e66caf3836f5ceb45f46dce08331b2f6eeee46fdb8c6f414734a4f10_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_45923ec3e66caf3836f5ceb45f46dce08331b2f6eeee46fdb8c6f414734a4f10_d.txt?sv=2019-02-02&sr=b&sig=LmVTJ0%2Bqv9MlqgKrt1L50mSJWe2bqKoSf6adlqUWtn0%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_4c186eff6bb17af2b4792b8b905856f73720b78f2a08de9b4eb6397a14400d35_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_4c186eff6bb17af2b4792b8b905856f73720b78f2a08de9b4eb6397a14400d35_d.txt?sv=2019-02-02&sr=b&sig=BcFpXngTN%2BIflTRJTDeqzilRAYmEazMCX5F9jCad8Tg%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_4f48c32cc392cf53c9b9b935ed4853296dd8c748e6a124113e86cd429cd85ac5_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_4f48c32cc392cf53c9b9b935ed4853296dd8c748e6a124113e86cd429cd85ac5_d.txt?sv=2019-02-02&sr=b&sig=QVINDl0VBJaXUuDK0VR6YeU5eisi%2BK5Cj0RpHauaXEA%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_56909ad7ba38d2863642af25f101df34d3c1a4487618f53e0dc997238c6c1f02_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_56909ad7ba38d2863642af25f101df34d3c1a4487618f53e0dc997238c6c1f02_d.txt?sv=2019-02-02&sr=b&sig=YxnVVw61ME7M7f9tu%2F%2FgUkn2iFORHrhONvf9%2BZ6tc50%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_5a026e3752c03bb5f217e2de46712cb40896a87aa84ac8b44eacbe0a0c31fb69_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_5a026e3752c03bb5f217e2de46712cb40896a87aa84ac8b44eacbe0a0c31fb69_d.txt?sv=2019-02-02&sr=b&sig=z0lL09wL41lLT654JZmLUWcJvrcCCehEaaNT8hUYXh8%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_5e425782132c9db391c72bc831dbea7918d03e8e7c00b6983f3a2ca195410654_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_5e425782132c9db391c72bc831dbea7918d03e8e7c00b6983f3a2ca195410654_d.txt?sv=2019-02-02&sr=b&sig=n22%2BinHEdZJRq5JgQ0%2FnIt38jSZ8tLjiiAfNyAnpxjc%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_6135c404470e13355d7db3c969d654994f703d069ea0e7f48ffd9f92bae4e482_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_6135c404470e13355d7db3c969d654994f703d069ea0e7f48ffd9f92bae4e482_d.txt?sv=2019-02-02&sr=b&sig=G7ozQyP0sgXlKnqbcoGSTebIYVvikhFqsgK6QrunqQE%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_63d543ababd6b9084721612575add1fb768d3358445bac67ac4f86373850782a_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_63d543ababd6b9084721612575add1fb768d3358445bac67ac4f86373850782a_d.txt?sv=2019-02-02&sr=b&sig=jj2YJYJPm14u8pEneyi0TZKZtQPeTNRNLNd1Yadvtq4%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_6b1cc718c25aa60f2fc15815d380b99f4741217140899901920f85d8537ccf2f_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_6b1cc718c25aa60f2fc15815d380b99f4741217140899901920f85d8537ccf2f_d.txt?sv=2019-02-02&sr=b&sig=J%2BPpw01GLS5SOIHRd6O5sTgry9AMIJg6oideMJ%2BSVKM%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_6bb3b15f6b598e71bd77d8732bcc408fc82b755f244ff6a1e6e001b410c13978_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_6bb3b15f6b598e71bd77d8732bcc408fc82b755f244ff6a1e6e001b410c13978_d.txt?sv=2019-02-02&sr=b&sig=MejEpoOSCkKy4U8dfbeB9H4nq%2FbVxNsigVJPvDFvjnQ%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_71347e775dd8fd5223e5b2492573825d87d5b1b7dc9c2c269cd6df55ae77886e_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_71347e775dd8fd5223e5b2492573825d87d5b1b7dc9c2c269cd6df55ae77886e_d.txt?sv=2019-02-02&sr=b&sig=35YeQbX%2BuTwWNsx0kdwpLiSdM23e4RXWVGKl5aUlcZU%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_7ff7e4c00de017e154d8d85601cbade5149c86caeae57624dd279b45b4573c21_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_7ff7e4c00de017e154d8d85601cbade5149c86caeae57624dd279b45b4573c21_d.txt?sv=2019-02-02&sr=b&sig=g5StOloz74xTeQp%2BAVe7F%2BA0dBwWOFGkrGL%2FbIkTA8w%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_82f7f8a698273a77771fab8ec470d9bfd1ee58cbf7342f9a4ab92b897fc889e6_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_82f7f8a698273a77771fab8ec470d9bfd1ee58cbf7342f9a4ab92b897fc889e6_d.txt?sv=2019-02-02&sr=b&sig=GdO59%2FaaGJr4HginRqgNOo1ZVIayD32qhXQ4qTrl3g4%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_840c29749640ef28a43490ca9000539fc840db38a10ebcd588733a9271a18afa_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_840c29749640ef28a43490ca9000539fc840db38a10ebcd588733a9271a18afa_d.txt?sv=2019-02-02&sr=b&sig=%2F9REOWn4ma02dixHcCIUlxKxKBG1SpG66ImtkpWLm3Y%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_879d4c33ffeb0e1f1c01c91be9b59f52c1a1d5cc5d8ed94d6627479c237bff6b_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_879d4c33ffeb0e1f1c01c91be9b59f52c1a1d5cc5d8ed94d6627479c237bff6b_d.txt?sv=2019-02-02&sr=b&sig=bPJYI9AvenqZ1f7X8IiSU0G48Po12ReD7usUBBBDnSc%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_87de78b3cd1df0a548db449a964fcd4397be889f3a1961f05a852b673a985ac9_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_87de78b3cd1df0a548db449a964fcd4397be889f3a1961f05a852b673a985ac9_d.txt?sv=2019-02-02&sr=b&sig=XyQzxOEGIEtyZoI2iOdU68RRzBob%2B7M0IRwxdHyOtP8%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_8c6d161a5ac2c3239e0d4e8aa6177d481844a9abcf438544e20dcf2854ffa046_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_8c6d161a5ac2c3239e0d4e8aa6177d481844a9abcf438544e20dcf2854ffa046_d.txt?sv=2019-02-02&sr=b&sig=SFdwL5K6Ee4R7v8xuor580bpB%2F0eDsAyx6n9p342VHk%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_8c7193ddaf89ee140a1770abed03537598705ff274c364d72af6240a4e2222c1_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_8c7193ddaf89ee140a1770abed03537598705ff274c364d72af6240a4e2222c1_d.txt?sv=2019-02-02&sr=b&sig=weTt4DIA9gjbOeRayLXQd1cZep3y6E2s%2BY%2Br2Y9RRB0%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_9490d2700178b9884b7bfebfcbc162742d64c653c54cf79aaf845830bd72d98c_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_9490d2700178b9884b7bfebfcbc162742d64c653c54cf79aaf845830bd72d98c_d.txt?sv=2019-02-02&sr=b&sig=Z%2FFZDqBCKnX55Sj7VQQjh2hW4bYAsXKIP%2BON%2BNAjj2o%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_a6fc3193127709481981a6b6f66391ff8ab7e12207973b6ac05f966db4e9c154_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_a6fc3193127709481981a6b6f66391ff8ab7e12207973b6ac05f966db4e9c154_d.txt?sv=2019-02-02&sr=b&sig=l021WABx3PRaIOmJlGBa0VC155T1hHErNOcmXT5VKYA%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_adfe188c01c849eb17cdf486445da78a3830b75a87931141af44e4e757bf480b_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_adfe188c01c849eb17cdf486445da78a3830b75a87931141af44e4e757bf480b_d.txt?sv=2019-02-02&sr=b&sig=aSEeq4zFo%2BWr3rlb0LVYykLWp09%2FAJJZxAJNZhL2mg8%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_b3b821ece8ff080140ace13484d9d299f9dfa4bc5ce843bbf1459d41f0beb9ce_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_b3b821ece8ff080140ace13484d9d299f9dfa4bc5ce843bbf1459d41f0beb9ce_d.txt?sv=2019-02-02&sr=b&sig=VS5rNC8SeYav23J%2B4FQCGBcK0bMGTDVtny4IBEs%2BQtE%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_b7821eaaf0d3c2a998c60c7d9a9e515e0532ee6725e6f13f6e7da24b8eb92737_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_b7821eaaf0d3c2a998c60c7d9a9e515e0532ee6725e6f13f6e7da24b8eb92737_d.txt?sv=2019-02-02&sr=b&sig=6CqCAknFR3TWNWuLA5jGDab9lxTHMozVhpqc9d7OcR4%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_bebf30f144e35d950b17b121a346f4104ba39ed8d2890327b260092b8d777e8f_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_bebf30f144e35d950b17b121a346f4104ba39ed8d2890327b260092b8d777e8f_d.txt?sv=2019-02-02&sr=b&sig=iqxeIwkFhhcEv8N1w7fO88M8%2BCHDlGPjOXQMBbHtf0g%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_c68e58265021296049e3857bd56b1ec05b7f1885493c92fc13d0cfd4fc5d1bd9_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_c68e58265021296049e3857bd56b1ec05b7f1885493c92fc13d0cfd4fc5d1bd9_d.txt?sv=2019-02-02&sr=b&sig=rJ4%2FjdbJ9R5y4y%2B4eKXohmJetqxDL10%2Bbn5RlCQE8RM%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_cf3d3dbaaa90cf7f574b1f41b3deb7aefaa59bb6b3c628d11cbd9f2ba1c8a8c3_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_cf3d3dbaaa90cf7f574b1f41b3deb7aefaa59bb6b3c628d11cbd9f2ba1c8a8c3_d.txt?sv=2019-02-02&sr=b&sig=mE2kxSZgPf47U6PARgy5nNG5vwdFuGpfKUnDN46dfz0%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_d65600ea0511e4610e38766c17f55bc518013770b0b1a0f8893239ef06440501_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_d65600ea0511e4610e38766c17f55bc518013770b0b1a0f8893239ef06440501_d.txt?sv=2019-02-02&sr=b&sig=ylQMt793eGQEYasiktlfnIltMcwt0FYtUVMvNhNl3SE%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_dcf6c9433e3d34089c934cfeae8a4fdcff0716dd362ab5e6ac18ad98213e86b9_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_dcf6c9433e3d34089c934cfeae8a4fdcff0716dd362ab5e6ac18ad98213e86b9_d.txt?sv=2019-02-02&sr=b&sig=a8p9rK8va7rrSdKpWSv08ywwFy1NKknm51aXBKMmcyE%3D&st=2020-01-12T23%3A54%3A28Z&se=2020-01-13T08%3A04%3A28Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_df523981408e4635f0a9965c17e4521a1452c18cd123625ba669717459664c44_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_df523981408e4635f0a9965c17e4521a1452c18cd123625ba669717459664c44_d.txt?sv=2019-02-02&sr=b&sig=aMzCANMfFmPikGi5E4yZ5dhEmyhKoUK8hkEdt9gK%2Fqo%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_e42dd5967f31fd649d74245073b382f18bed0f445e0712a72c6b78cf3ea31030_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_e42dd5967f31fd649d74245073b382f18bed0f445e0712a72c6b78cf3ea31030_d.txt?sv=2019-02-02&sr=b&sig=ZoCnC9G%2FGiFMxMyGvEVAgEoN%2B8o5E%2BQ3Wpu%2BeO%2BKz8w%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_e886e5978634d1e3de6db014b7e59be2381966fd81f20167b7815eb01b117ec7_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_e886e5978634d1e3de6db014b7e59be2381966fd81f20167b7815eb01b117ec7_d.txt?sv=2019-02-02&sr=b&sig=bQwlm0MGeCD772kcFIHG0pS0QT1GbrkfJytTudWnmrk%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_faf0c0aa3f34d8c35cf164c167f0062c54199921b0099c4f10e28b15dfabe4b8_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_faf0c0aa3f34d8c35cf164c167f0062c54199921b0099c4f10e28b15dfabe4b8_d.txt?sv=2019-02-02&sr=b&sig=E4nxOOcKqAcYr8EUtd5ahIa8Xb%2FozYIuFLv3KmBB3ok%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_fb3bdcaccbf592841e5f147457edfbfe7aeec01ae53be40f85bb4d732b799066_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_fb3bdcaccbf592841e5f147457edfbfe7aeec01ae53be40f85bb4d732b799066_d.txt?sv=2019-02-02&sr=b&sig=g6iwgmhWv%2BJr9%2FEEHizGsZZ7QUoQ1BmZtOnOrV%2FgnXY%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/55_azureml-execution-tvmps_fcccfb8cfeeeb814ff46dc0121d18a3a1dd372ad2da4993c5bb1e1afa33a06ed_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/55_azureml-execution-tvmps_fcccfb8cfeeeb814ff46dc0121d18a3a1dd372ad2da4993c5bb1e1afa33a06ed_d.txt?sv=2019-02-02&sr=b&sig=2E0n8Df1BaRNEK9OeMDB4dEHIXKeh0IDvlK1%2Bdt7sGA%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_08ba4fc2564c12e743f9c7ee0d5ee30f59f2b026d795f29cd0148f1b1d70780f_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_08ba4fc2564c12e743f9c7ee0d5ee30f59f2b026d795f29cd0148f1b1d70780f_d.txt?sv=2019-02-02&sr=b&sig=6YQkZenvqaPzGQ15epwbFEU5OVW3eDOWuAavY1OHCEo%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_1659e1dace2241c029d647263ff2a51ede9d9c003bdf45673109c8c81b00ee24_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_1659e1dace2241c029d647263ff2a51ede9d9c003bdf45673109c8c81b00ee24_d.txt?sv=2019-02-02&sr=b&sig=Uq2%2FZDmvsV0mEwtRxkpWquhGTfrqU7DnD9qKurhzWJg%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_1e5482d9b0b6288f35c5dfbb022cf63e77b87ccf7b918bc3fd080ae288818cd7_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_1e5482d9b0b6288f35c5dfbb022cf63e77b87ccf7b918bc3fd080ae288818cd7_d.txt?sv=2019-02-02&sr=b&sig=mQk8RnjXslWo6QfX7f7AuH%2Bhm0AKix1JcZh4CeiqRjM%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_2c3a415254f21fd09c8ce8aebfa60ff7e9ec296ea21506293f4bf0564ad586a0_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_2c3a415254f21fd09c8ce8aebfa60ff7e9ec296ea21506293f4bf0564ad586a0_d.txt?sv=2019-02-02&sr=b&sig=G26WdPyQoOToerpQS%2FQH5y1YiiyqtIl7AuhdS7O2qoM%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_3c776006b52538e1bbf82873aec75313d85170583b552aad04f85de9469612c1_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_3c776006b52538e1bbf82873aec75313d85170583b552aad04f85de9469612c1_d.txt?sv=2019-02-02&sr=b&sig=MzBDM2%2BsTtWsx7%2F535CI6upwECiPIYqKY9oIRKidc2w%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_44f2233f2aafccc8182330cb3e3ba7ec642ef8e8e55074ed484cde6b1ae103ab_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_44f2233f2aafccc8182330cb3e3ba7ec642ef8e8e55074ed484cde6b1ae103ab_d.txt?sv=2019-02-02&sr=b&sig=HKX%2B1HIdnK2%2BDkO3mr03pkgLjfasWhClctXvUKWLBfs%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_45923ec3e66caf3836f5ceb45f46dce08331b2f6eeee46fdb8c6f414734a4f10_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_45923ec3e66caf3836f5ceb45f46dce08331b2f6eeee46fdb8c6f414734a4f10_d.txt?sv=2019-02-02&sr=b&sig=YkSI41b551Yb0iLhhA2OLGjV6jVIoHRbYvFunOqgQFc%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_4c186eff6bb17af2b4792b8b905856f73720b78f2a08de9b4eb6397a14400d35_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_4c186eff6bb17af2b4792b8b905856f73720b78f2a08de9b4eb6397a14400d35_d.txt?sv=2019-02-02&sr=b&sig=sedfu%2FwHHCP2GMajTNYNvSufNuCJ%2BPm7Cd120eoAsag%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_4f48c32cc392cf53c9b9b935ed4853296dd8c748e6a124113e86cd429cd85ac5_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_4f48c32cc392cf53c9b9b935ed4853296dd8c748e6a124113e86cd429cd85ac5_d.txt?sv=2019-02-02&sr=b&sig=8%2BV3qkYo1XgKtXHFAPvjE7j3UHJCmsY6I%2Bp%2FZH%2BfdC8%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_56909ad7ba38d2863642af25f101df34d3c1a4487618f53e0dc997238c6c1f02_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_56909ad7ba38d2863642af25f101df34d3c1a4487618f53e0dc997238c6c1f02_d.txt?sv=2019-02-02&sr=b&sig=h5GtB9MixzQSXpWcNXJ%2F1ZXS0pVntvtQyRsDfn4i0bs%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_5a026e3752c03bb5f217e2de46712cb40896a87aa84ac8b44eacbe0a0c31fb69_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_5a026e3752c03bb5f217e2de46712cb40896a87aa84ac8b44eacbe0a0c31fb69_d.txt?sv=2019-02-02&sr=b&sig=nundbbcFtUpUrIjEOZSJlbmuYL%2F9SOoFvnac1Cgjfqk%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_5e425782132c9db391c72bc831dbea7918d03e8e7c00b6983f3a2ca195410654_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_5e425782132c9db391c72bc831dbea7918d03e8e7c00b6983f3a2ca195410654_d.txt?sv=2019-02-02&sr=b&sig=aAly5GWZvd0k%2BG5y8O6sJt1ocIvsSD3FVvjsHcuvqHY%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_6135c404470e13355d7db3c969d654994f703d069ea0e7f48ffd9f92bae4e482_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_6135c404470e13355d7db3c969d654994f703d069ea0e7f48ffd9f92bae4e482_d.txt?sv=2019-02-02&sr=b&sig=cdr7oI5b%2BXOPYT0hLAERk0XB7SRSf1LTn%2BLdPmXzCwc%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_63d543ababd6b9084721612575add1fb768d3358445bac67ac4f86373850782a_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_63d543ababd6b9084721612575add1fb768d3358445bac67ac4f86373850782a_d.txt?sv=2019-02-02&sr=b&sig=RF49mqxG4KRhGSQJ2%2BgVb1klWnPumibs10ZDCtroNLU%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_6b1cc718c25aa60f2fc15815d380b99f4741217140899901920f85d8537ccf2f_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_6b1cc718c25aa60f2fc15815d380b99f4741217140899901920f85d8537ccf2f_d.txt?sv=2019-02-02&sr=b&sig=kTcKHZ4LiZWym%2BXceCZdL251YWk92aK0sTv6n3JXb%2Bg%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_6bb3b15f6b598e71bd77d8732bcc408fc82b755f244ff6a1e6e001b410c13978_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_6bb3b15f6b598e71bd77d8732bcc408fc82b755f244ff6a1e6e001b410c13978_d.txt?sv=2019-02-02&sr=b&sig=mTiq8hZ0nNiCXavTBBEfJMIws8r%2BM8lLIEO7nJAHWRg%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_71347e775dd8fd5223e5b2492573825d87d5b1b7dc9c2c269cd6df55ae77886e_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_71347e775dd8fd5223e5b2492573825d87d5b1b7dc9c2c269cd6df55ae77886e_d.txt?sv=2019-02-02&sr=b&sig=gdAgNkvi%2B3vNdEPFxUK7nO7ZNysE6S9RMlQd%2FFraTz4%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_7ff7e4c00de017e154d8d85601cbade5149c86caeae57624dd279b45b4573c21_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_7ff7e4c00de017e154d8d85601cbade5149c86caeae57624dd279b45b4573c21_d.txt?sv=2019-02-02&sr=b&sig=akCu5FKMNYgZ4vkxif%2Br5tkyu6UfH7d536NqydXeQsQ%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_82f7f8a698273a77771fab8ec470d9bfd1ee58cbf7342f9a4ab92b897fc889e6_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_82f7f8a698273a77771fab8ec470d9bfd1ee58cbf7342f9a4ab92b897fc889e6_d.txt?sv=2019-02-02&sr=b&sig=FI1P0fV984dNzhuaXtlCi0nnl0dQQaPxeYlvTup8o20%3D&st=2020-01-12T23%3A54%3A29Z&se=2020-01-13T08%3A04%3A29Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_840c29749640ef28a43490ca9000539fc840db38a10ebcd588733a9271a18afa_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_840c29749640ef28a43490ca9000539fc840db38a10ebcd588733a9271a18afa_d.txt?sv=2019-02-02&sr=b&sig=iS854dHKFNfNX9q6M3iYDniM6gndNFMEcJilUJgUS5s%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_879d4c33ffeb0e1f1c01c91be9b59f52c1a1d5cc5d8ed94d6627479c237bff6b_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_879d4c33ffeb0e1f1c01c91be9b59f52c1a1d5cc5d8ed94d6627479c237bff6b_d.txt?sv=2019-02-02&sr=b&sig=dUJghmKBaKo5f99DoLuYBMIWI1yyX7BaYQ0oa1HGjOk%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_87de78b3cd1df0a548db449a964fcd4397be889f3a1961f05a852b673a985ac9_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_87de78b3cd1df0a548db449a964fcd4397be889f3a1961f05a852b673a985ac9_d.txt?sv=2019-02-02&sr=b&sig=rtcjMiDlcRuEPQsZ8TUsK34JZnvqTPhScMhg1Cu2%2BZ4%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_8c6d161a5ac2c3239e0d4e8aa6177d481844a9abcf438544e20dcf2854ffa046_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_8c6d161a5ac2c3239e0d4e8aa6177d481844a9abcf438544e20dcf2854ffa046_d.txt?sv=2019-02-02&sr=b&sig=IgmFK7CLqjI6Dlj%2FZ%2Fznbxj9SEUmRhR3u4REysYNAb4%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_8c7193ddaf89ee140a1770abed03537598705ff274c364d72af6240a4e2222c1_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_8c7193ddaf89ee140a1770abed03537598705ff274c364d72af6240a4e2222c1_d.txt?sv=2019-02-02&sr=b&sig=O79nV%2FB%2BlhJl13ugRXMosAxj3Ph5FQf5jhM7Es%2F5%2BvY%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_9490d2700178b9884b7bfebfcbc162742d64c653c54cf79aaf845830bd72d98c_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_9490d2700178b9884b7bfebfcbc162742d64c653c54cf79aaf845830bd72d98c_d.txt?sv=2019-02-02&sr=b&sig=A2eCds8zqI4aQDrnhnB%2FdzesMWb2c5x7Q1qy7cGDCRw%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_a6fc3193127709481981a6b6f66391ff8ab7e12207973b6ac05f966db4e9c154_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_a6fc3193127709481981a6b6f66391ff8ab7e12207973b6ac05f966db4e9c154_d.txt?sv=2019-02-02&sr=b&sig=wrV17b%2FFrOdvzzTx%2F%2F5vU9Q1qYnOwHtjss9w0odq8FE%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_adfe188c01c849eb17cdf486445da78a3830b75a87931141af44e4e757bf480b_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_adfe188c01c849eb17cdf486445da78a3830b75a87931141af44e4e757bf480b_d.txt?sv=2019-02-02&sr=b&sig=5%2Byht42wXbftG6DtI6InB%2Fa%2BoKMJ9%2FDADStB8S9lrPg%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_b3b821ece8ff080140ace13484d9d299f9dfa4bc5ce843bbf1459d41f0beb9ce_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_b3b821ece8ff080140ace13484d9d299f9dfa4bc5ce843bbf1459d41f0beb9ce_d.txt?sv=2019-02-02&sr=b&sig=Wv2zXG889AZaoqcMlDtaJhgpSwhGYsZHrrE3GfwNkCs%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_b7821eaaf0d3c2a998c60c7d9a9e515e0532ee6725e6f13f6e7da24b8eb92737_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_b7821eaaf0d3c2a998c60c7d9a9e515e0532ee6725e6f13f6e7da24b8eb92737_d.txt?sv=2019-02-02&sr=b&sig=gJEvbmjorPhFoyedccioQ8UM9nQfJvHARVaPiqhvURc%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_bebf30f144e35d950b17b121a346f4104ba39ed8d2890327b260092b8d777e8f_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_bebf30f144e35d950b17b121a346f4104ba39ed8d2890327b260092b8d777e8f_d.txt?sv=2019-02-02&sr=b&sig=rdr582l%2FRE3WC4PmZZLgzqDAlgwTZJjxuAiCJuArmGQ%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_c68e58265021296049e3857bd56b1ec05b7f1885493c92fc13d0cfd4fc5d1bd9_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_c68e58265021296049e3857bd56b1ec05b7f1885493c92fc13d0cfd4fc5d1bd9_d.txt?sv=2019-02-02&sr=b&sig=Gvw46MLbIa9xCXMiQCvkHO4UD0SiZnQAg2MEopAqPh4%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_cf3d3dbaaa90cf7f574b1f41b3deb7aefaa59bb6b3c628d11cbd9f2ba1c8a8c3_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_cf3d3dbaaa90cf7f574b1f41b3deb7aefaa59bb6b3c628d11cbd9f2ba1c8a8c3_d.txt?sv=2019-02-02&sr=b&sig=RhfE3fhUUWNvwBiwqCMJ0Tx1%2FYmvIrpFnM%2FePrU3tvQ%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_d65600ea0511e4610e38766c17f55bc518013770b0b1a0f8893239ef06440501_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_d65600ea0511e4610e38766c17f55bc518013770b0b1a0f8893239ef06440501_d.txt?sv=2019-02-02&sr=b&sig=VxuKFjFvf3V09YizUEbb7VGAwkCjC%2FgHsiyrUzaQbGY%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_dcf6c9433e3d34089c934cfeae8a4fdcff0716dd362ab5e6ac18ad98213e86b9_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_dcf6c9433e3d34089c934cfeae8a4fdcff0716dd362ab5e6ac18ad98213e86b9_d.txt?sv=2019-02-02&sr=b&sig=Fvav9CMdTB1bgwzfb5HiPTsYYhV%2BaXGYNj%2FJDysZsgA%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_df523981408e4635f0a9965c17e4521a1452c18cd123625ba669717459664c44_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_df523981408e4635f0a9965c17e4521a1452c18cd123625ba669717459664c44_d.txt?sv=2019-02-02&sr=b&sig=CGDDjBPUDW7sx9sBo91XcCZGr%2BPARzWFMzxiV9ZYJN8%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_e42dd5967f31fd649d74245073b382f18bed0f445e0712a72c6b78cf3ea31030_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_e42dd5967f31fd649d74245073b382f18bed0f445e0712a72c6b78cf3ea31030_d.txt?sv=2019-02-02&sr=b&sig=w7tYp90taZ3XZ8mQBLKgxMBufJFDotqOHyitDm02%2FuA%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_e886e5978634d1e3de6db014b7e59be2381966fd81f20167b7815eb01b117ec7_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_e886e5978634d1e3de6db014b7e59be2381966fd81f20167b7815eb01b117ec7_d.txt?sv=2019-02-02&sr=b&sig=SjdefVgEUESIp999RRMKIRg7pQ28EsE4ywkkp8FPUfE%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_faf0c0aa3f34d8c35cf164c167f0062c54199921b0099c4f10e28b15dfabe4b8_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_faf0c0aa3f34d8c35cf164c167f0062c54199921b0099c4f10e28b15dfabe4b8_d.txt?sv=2019-02-02&sr=b&sig=RmXj1gRLF08hZz6%2FzW1%2FNFeUz%2B81m4tc5PxEyCvnOgM%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_fb3bdcaccbf592841e5f147457edfbfe7aeec01ae53be40f85bb4d732b799066_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_fb3bdcaccbf592841e5f147457edfbfe7aeec01ae53be40f85bb4d732b799066_d.txt?sv=2019-02-02&sr=b&sig=UIm9DTxMBKeRIX844z3Wva%2BRvajL8md3gn9rbQvTuLQ%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_fcccfb8cfeeeb814ff46dc0121d18a3a1dd372ad2da4993c5bb1e1afa33a06ed_d.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/65_job_prep-tvmps_fcccfb8cfeeeb814ff46dc0121d18a3a1dd372ad2da4993c5bb1e1afa33a06ed_d.txt?sv=2019-02-02&sr=b&sig=IXB%2BMj8abizd41U2PQ4HCbvNOjZ6BhsXt5W%2F%2BNLUDSE%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/70_driver_log_0.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_0.txt?sv=2019-02-02&sr=b&sig=J%2FSRwAzGSilG5BcSklIWed%2F8JprffC%2FqC3crMYAVOwE%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/70_driver_log_1.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_1.txt?sv=2019-02-02&sr=b&sig=N94v1cyDOGjwuhhqrXhz6h8HOehVB8KAJ4PDm87nX5c%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/70_driver_log_10.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_10.txt?sv=2019-02-02&sr=b&sig=Jx4xjV4MXxeMfZ6YNGoLky%2BTUswRwTdqEoXWCY4BfyE%3D&st=2020-01-12T23%3A54%3A30Z&se=2020-01-13T08%3A04%3A30Z&sp=r\", \"azureml-logs/70_driver_log_11.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_11.txt?sv=2019-02-02&sr=b&sig=Spnx%2BvodGgaehfcAjYaJ%2BP4grStt4IyFLZXqVD6kPxw%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_12.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_12.txt?sv=2019-02-02&sr=b&sig=maWEWJaZ5GN2XNixP0ktvRydxe92gMj2sZlseEVqBvQ%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_13.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_13.txt?sv=2019-02-02&sr=b&sig=B2zoRTYrZQMQhIXNWkzX8lr7CsIjKFIFO9ZnlBsaoGI%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_14.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_14.txt?sv=2019-02-02&sr=b&sig=kSSVRO7CWDHexUerWdjriDTMA0xObOrI9GiWx3n5oiE%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_15.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_15.txt?sv=2019-02-02&sr=b&sig=ESkb7EFYr5C62MAqbGtl4AR4jW%2FaKDeCtr0sZOeJZ9Y%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_16.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_16.txt?sv=2019-02-02&sr=b&sig=nm%2BLsf%2F6KIRozMLRNFtF8ABlnWg%2Fhd1W3TOcjeB5iZA%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_17.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_17.txt?sv=2019-02-02&sr=b&sig=ZGaFlFN0OkSO2M0FviYD0081PHbyoJopmtNbLZJ5Zog%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_18.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_18.txt?sv=2019-02-02&sr=b&sig=xr1ct3h0flu6XDfTMNO1SEr8eA1rBiS%2FUMlTOUky19U%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_19.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_19.txt?sv=2019-02-02&sr=b&sig=hi89%2F3CvEVkxiYmPQWEj%2FQpcYFa0Pq7h7RfQxuirMPk%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_2.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_2.txt?sv=2019-02-02&sr=b&sig=2d9lqpH7Z0KjTplko9dk5ElhtzBreHgGiZWwMOduWsU%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_20.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_20.txt?sv=2019-02-02&sr=b&sig=yOO1R8nnrBvOAaqQq6fvb6%2FmV2l9XS%2FiELXmjentHSI%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_21.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_21.txt?sv=2019-02-02&sr=b&sig=2nBvaaRkyshv1CQ15xptpQRDg9%2BZStRdiqiY30Esf7Q%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_22.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_22.txt?sv=2019-02-02&sr=b&sig=hAW0r4aBZ3%2BAkDDu%2B95OEangsC6UpH9a0G67rzpSa%2F4%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_23.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_23.txt?sv=2019-02-02&sr=b&sig=Eilq52e2R1UHcKPUeBM88VORB9tljYWD6VNVWvUbHPs%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_24.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_24.txt?sv=2019-02-02&sr=b&sig=KCY2GU3%2FtuCCYglS%2F15Qf%2BY%2Bqkd38vxezUomqzRqRic%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_25.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_25.txt?sv=2019-02-02&sr=b&sig=5r2J318byozA8mQIl3RI6vG782i08yb3FXZjK1DLwpU%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"azureml-logs/70_driver_log_26.txt\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/azureml-logs/70_driver_log_26.txt?sv=2019-02-02&sr=b&sig=PO2ZYI8huy5f6VUmozf%2FGVYgkTIscFdjwxakr4UVH7E%3D&st=2020-01-12T23%3A54%3A31Z&se=2020-01-13T08%3A04%3A31Z&sp=r\", \"logs/azureml/0_217_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/0_217_azureml.log?sv=2019-02-02&sr=b&sig=maeGufgHoA7mPNvqNRQ2H83iRPaSfMBZcgG%2BtRdjCcI%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/10_134_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/10_134_azureml.log?sv=2019-02-02&sr=b&sig=xSjv%2BJpOWYMIghzala0gIP9PXcHmhRaC4t9kIm22pSU%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/11_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/11_135_azureml.log?sv=2019-02-02&sr=b&sig=OzAsL5TwoFvlvmFws20G2qpf5oA27BmOFUcP8HAeI2Y%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/12_133_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/12_133_azureml.log?sv=2019-02-02&sr=b&sig=k7J%2B3fTt5xtoxHesidvyjZrGEn5bLQv5V3e9HlAtZBw%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/13_134_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/13_134_azureml.log?sv=2019-02-02&sr=b&sig=qwjg0GvPev0eXJBu0rjG02iNsQg6Azi%2FqrzWNaBB5bc%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/14_136_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/14_136_azureml.log?sv=2019-02-02&sr=b&sig=PrRPcKM1GUN7W3Rk1p4bjNo3rKa20D8tXA87EiZnr20%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/15_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/15_135_azureml.log?sv=2019-02-02&sr=b&sig=cfUOnd9jj4q%2FzhKKo0pgJKM5pXAHkyfWtijBA0fncQU%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/16_136_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/16_136_azureml.log?sv=2019-02-02&sr=b&sig=4jq3wMzL2XpW%2BjvDOX%2BAr%2B2I5NgTekr03HMvu0otwz8%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/17_134_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/17_134_azureml.log?sv=2019-02-02&sr=b&sig=jkJtcTqEEZ3l8TW%2BM57KmjdMsNithZx4QxQKxZB%2BOnQ%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/18_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/18_135_azureml.log?sv=2019-02-02&sr=b&sig=nqsQYjoA%2BXVVQjRTZy0k7XnBSU7EL7NmUwPrYEShXiA%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/19_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/19_135_azureml.log?sv=2019-02-02&sr=b&sig=aIO26cfFQiHT%2F0r071DoqSyTi6UU5GEgKWed%2BEpeZl8%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/1_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/1_135_azureml.log?sv=2019-02-02&sr=b&sig=PAYEP1o7DVQ4GqGGlmL%2BcznmA7ci%2FPvs6dikYiTNhUI%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/20_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/20_135_azureml.log?sv=2019-02-02&sr=b&sig=msTjV3e2%2F6a7pID5gPK%2Fb630ZvmYK4q9E%2FS5K65vVao%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/21_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/21_135_azureml.log?sv=2019-02-02&sr=b&sig=bf4qRawO%2FsG29QHMrj44XEnpxqWGIjimq4f9McNaaFU%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/22_134_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/22_134_azureml.log?sv=2019-02-02&sr=b&sig=ISGZcjVjCPh41MRDeFAJz1uQsY3uj4nITqvpOyFtuvE%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/23_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/23_135_azureml.log?sv=2019-02-02&sr=b&sig=7A2qEWK9h%2F4fA0%2BapXCp4qIWN2yVDaGqAiWI7etsVaw%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/24_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/24_135_azureml.log?sv=2019-02-02&sr=b&sig=CClJPWJH4zbRzM9UXcYiSXlHVQizwBQ%2BujjHq2qjFu8%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/25_134_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/25_134_azureml.log?sv=2019-02-02&sr=b&sig=2cLLNHT7I0DSKZIJds%2B4DhVooIofX%2B6rehULcrvGXco%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/26_134_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/26_134_azureml.log?sv=2019-02-02&sr=b&sig=uaMwwHYqqzIkDcj9TT%2F6oUz1pEcLISaaQ2HB9r9PrUY%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/27_134_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/27_134_azureml.log?sv=2019-02-02&sr=b&sig=Xe0wWVm8KLdIkWVPt%2FxPJp3W1hS9RP0gTUt79fqTr0Q%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/28_134_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/28_134_azureml.log?sv=2019-02-02&sr=b&sig=aWHGHMOMcBPg%2FM4dWtbfq1uGTKoeTJ7XHn63dY%2B7imE%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/29_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/29_135_azureml.log?sv=2019-02-02&sr=b&sig=82kwnCM8gb5iGvKHA6XUIUXEkGQ7Umq%2FnlCsxOGwFcM%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/2_136_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/2_136_azureml.log?sv=2019-02-02&sr=b&sig=MKqN%2Bt%2Fy448CBfBox5qEam1%2BinMHYNSmtrw4H5kcP0c%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/30_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/30_135_azureml.log?sv=2019-02-02&sr=b&sig=voBsSKAn4BaZvwELz5dB8f2WbTsMSyl0i3iSTaxX7g8%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/31_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/31_135_azureml.log?sv=2019-02-02&sr=b&sig=TtqfVHd0%2FQe%2FRwzUdv84TqU53zH2S8Md8tHA7gz2UB4%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/32_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/32_135_azureml.log?sv=2019-02-02&sr=b&sig=wPRIhIalaJIMJ1UYp4UIecSW%2BIm3vwWJpUPKDrwVNpc%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/33_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/33_135_azureml.log?sv=2019-02-02&sr=b&sig=X6gNBlKJlSqF3tbOd5GRvNjFCMj3ioZRON%2Fca2CJl04%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/34_134_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/34_134_azureml.log?sv=2019-02-02&sr=b&sig=uEN7T0jGGZTVE0FEkzL7sYRTCMUzNQ0BMJbw8UR1Dcg%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/35_134_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/35_134_azureml.log?sv=2019-02-02&sr=b&sig=lz3NDAWlpmyaYmB3pT1QSzGcwqz4RjEdBXlZJ28iokI%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/36_133_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/36_133_azureml.log?sv=2019-02-02&sr=b&sig=Flw2QyysHELuuSV8G1JkM20VbaKGE3HOIOnuC6qU6Uk%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/37_134_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/37_134_azureml.log?sv=2019-02-02&sr=b&sig=am5GFhDzzNvZ7466mCsyj8ppU42ZFArOecSsmIEtu64%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/38_134_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/38_134_azureml.log?sv=2019-02-02&sr=b&sig=yQgQml48JjvCXkwIV3%2FFQwyjOvyrl02opChQWk%2BuNW8%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/39_134_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/39_134_azureml.log?sv=2019-02-02&sr=b&sig=bT%2F1jmUngB6rNvZ6LhJ7l0OrfPcg8%2F0BC893d11jcWo%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/3_134_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/3_134_azureml.log?sv=2019-02-02&sr=b&sig=g1wwIRaHpKeji1CTKdU4MjYbfd1rGaC%2F5k8LqBtOwlg%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/4_134_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/4_134_azureml.log?sv=2019-02-02&sr=b&sig=rk1yhZz9rfcPZuq%2FN8d7raX2Q7kOPQkDwDLUhAzlReU%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/5_136_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/5_136_azureml.log?sv=2019-02-02&sr=b&sig=1Bo5ODxKUOpfWvF2epV1uBClBieTx2APjSvnLvFi7AI%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/6_133_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/6_133_azureml.log?sv=2019-02-02&sr=b&sig=GlDsi0RYJ4ZLBEwV5GdlN9Fzmi86G7XrI5208XZFVIQ%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/7_136_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/7_136_azureml.log?sv=2019-02-02&sr=b&sig=8NI28r5erEwfX9FeM%2F3bIYeOxF0NhmiR4I0qz8VqJxQ%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/8_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/8_135_azureml.log?sv=2019-02-02&sr=b&sig=v9GCfplMhwktHjQcBnaRvxKV02IuNUwreh%2BqH4nc8rg%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/9_135_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/9_135_azureml.log?sv=2019-02-02&sr=b&sig=0ZKjrr%2FJ7Eq2RYyHtR56GbUejyQEFIc64hoz2wYR8uE%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://ncusazureml4607512089.blob.core.windows.net/azureml/ExperimentRun/dcid.dask-xgboost_1578872294_ecf303d5/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=elr%2BqTYLGrxMKaDwXChP%2Ff4vAUBObJTD6LdduCoI3jQ%3D&st=2020-01-12T23%3A54%3A27Z&se=2020-01-13T08%3A04%3A27Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/job_prep_azureml.log\"], [\"logs/azureml/0_217_azureml.log\"], [\"logs/azureml/1_135_azureml.log\"], [\"logs/azureml/2_136_azureml.log\"], [\"logs/azureml/3_134_azureml.log\"], [\"logs/azureml/4_134_azureml.log\"], [\"logs/azureml/5_136_azureml.log\"], [\"logs/azureml/6_133_azureml.log\"], [\"logs/azureml/7_136_azureml.log\"], [\"logs/azureml/8_135_azureml.log\"], [\"logs/azureml/9_135_azureml.log\"], [\"logs/azureml/10_134_azureml.log\"], [\"logs/azureml/11_135_azureml.log\"], [\"logs/azureml/12_133_azureml.log\"], [\"logs/azureml/13_134_azureml.log\"], [\"logs/azureml/14_136_azureml.log\"], [\"logs/azureml/15_135_azureml.log\"], [\"logs/azureml/16_136_azureml.log\"], [\"logs/azureml/17_134_azureml.log\"], [\"logs/azureml/18_135_azureml.log\"], [\"logs/azureml/19_135_azureml.log\"], [\"logs/azureml/20_135_azureml.log\"], [\"logs/azureml/21_135_azureml.log\"], [\"logs/azureml/22_134_azureml.log\"], [\"logs/azureml/23_135_azureml.log\"], [\"logs/azureml/24_135_azureml.log\"], [\"logs/azureml/25_134_azureml.log\"], [\"logs/azureml/26_134_azureml.log\"], [\"logs/azureml/27_134_azureml.log\"], [\"logs/azureml/28_134_azureml.log\"], [\"logs/azureml/29_135_azureml.log\"], [\"logs/azureml/30_135_azureml.log\"], [\"logs/azureml/31_135_azureml.log\"], [\"logs/azureml/32_135_azureml.log\"], [\"logs/azureml/33_135_azureml.log\"], [\"logs/azureml/34_134_azureml.log\"], [\"logs/azureml/35_134_azureml.log\"], [\"logs/azureml/36_133_azureml.log\"], [\"logs/azureml/37_134_azureml.log\"], [\"logs/azureml/38_134_azureml.log\"], [\"logs/azureml/39_134_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_faf0c0aa3f34d8c35cf164c167f0062c54199921b0099c4f10e28b15dfabe4b8_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_1e5482d9b0b6288f35c5dfbb022cf63e77b87ccf7b918bc3fd080ae288818cd7_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_2c3a415254f21fd09c8ce8aebfa60ff7e9ec296ea21506293f4bf0564ad586a0_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_cf3d3dbaaa90cf7f574b1f41b3deb7aefaa59bb6b3c628d11cbd9f2ba1c8a8c3_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_b3b821ece8ff080140ace13484d9d299f9dfa4bc5ce843bbf1459d41f0beb9ce_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_fb3bdcaccbf592841e5f147457edfbfe7aeec01ae53be40f85bb4d732b799066_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_3c776006b52538e1bbf82873aec75313d85170583b552aad04f85de9469612c1_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_4f48c32cc392cf53c9b9b935ed4853296dd8c748e6a124113e86cd429cd85ac5_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_4c186eff6bb17af2b4792b8b905856f73720b78f2a08de9b4eb6397a14400d35_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_5a026e3752c03bb5f217e2de46712cb40896a87aa84ac8b44eacbe0a0c31fb69_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_5e425782132c9db391c72bc831dbea7918d03e8e7c00b6983f3a2ca195410654_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_6b1cc718c25aa60f2fc15815d380b99f4741217140899901920f85d8537ccf2f_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_6bb3b15f6b598e71bd77d8732bcc408fc82b755f244ff6a1e6e001b410c13978_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_dcf6c9433e3d34089c934cfeae8a4fdcff0716dd362ab5e6ac18ad98213e86b9_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_a6fc3193127709481981a6b6f66391ff8ab7e12207973b6ac05f966db4e9c154_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_7ff7e4c00de017e154d8d85601cbade5149c86caeae57624dd279b45b4573c21_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_08ba4fc2564c12e743f9c7ee0d5ee30f59f2b026d795f29cd0148f1b1d70780f_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_8c6d161a5ac2c3239e0d4e8aa6177d481844a9abcf438544e20dcf2854ffa046_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_fcccfb8cfeeeb814ff46dc0121d18a3a1dd372ad2da4993c5bb1e1afa33a06ed_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_8c7193ddaf89ee140a1770abed03537598705ff274c364d72af6240a4e2222c1_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_bebf30f144e35d950b17b121a346f4104ba39ed8d2890327b260092b8d777e8f_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_e42dd5967f31fd649d74245073b382f18bed0f445e0712a72c6b78cf3ea31030_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_44f2233f2aafccc8182330cb3e3ba7ec642ef8e8e55074ed484cde6b1ae103ab_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_63d543ababd6b9084721612575add1fb768d3358445bac67ac4f86373850782a_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_c68e58265021296049e3857bd56b1ec05b7f1885493c92fc13d0cfd4fc5d1bd9_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_82f7f8a698273a77771fab8ec470d9bfd1ee58cbf7342f9a4ab92b897fc889e6_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_87de78b3cd1df0a548db449a964fcd4397be889f3a1961f05a852b673a985ac9_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_adfe188c01c849eb17cdf486445da78a3830b75a87931141af44e4e757bf480b_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_840c29749640ef28a43490ca9000539fc840db38a10ebcd588733a9271a18afa_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_879d4c33ffeb0e1f1c01c91be9b59f52c1a1d5cc5d8ed94d6627479c237bff6b_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_e886e5978634d1e3de6db014b7e59be2381966fd81f20167b7815eb01b117ec7_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_1659e1dace2241c029d647263ff2a51ede9d9c003bdf45673109c8c81b00ee24_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_6135c404470e13355d7db3c969d654994f703d069ea0e7f48ffd9f92bae4e482_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_b7821eaaf0d3c2a998c60c7d9a9e515e0532ee6725e6f13f6e7da24b8eb92737_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_9490d2700178b9884b7bfebfcbc162742d64c653c54cf79aaf845830bd72d98c_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_45923ec3e66caf3836f5ceb45f46dce08331b2f6eeee46fdb8c6f414734a4f10_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_56909ad7ba38d2863642af25f101df34d3c1a4487618f53e0dc997238c6c1f02_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_d65600ea0511e4610e38766c17f55bc518013770b0b1a0f8893239ef06440501_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_71347e775dd8fd5223e5b2492573825d87d5b1b7dc9c2c269cd6df55ae77886e_d.txt\", \"azureml-logs/55_azureml-execution-tvmps_df523981408e4635f0a9965c17e4521a1452c18cd123625ba669717459664c44_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_faf0c0aa3f34d8c35cf164c167f0062c54199921b0099c4f10e28b15dfabe4b8_d.txt\", \"azureml-logs/65_job_prep-tvmps_1e5482d9b0b6288f35c5dfbb022cf63e77b87ccf7b918bc3fd080ae288818cd7_d.txt\", \"azureml-logs/65_job_prep-tvmps_2c3a415254f21fd09c8ce8aebfa60ff7e9ec296ea21506293f4bf0564ad586a0_d.txt\", \"azureml-logs/65_job_prep-tvmps_cf3d3dbaaa90cf7f574b1f41b3deb7aefaa59bb6b3c628d11cbd9f2ba1c8a8c3_d.txt\", \"azureml-logs/65_job_prep-tvmps_b3b821ece8ff080140ace13484d9d299f9dfa4bc5ce843bbf1459d41f0beb9ce_d.txt\", \"azureml-logs/65_job_prep-tvmps_fb3bdcaccbf592841e5f147457edfbfe7aeec01ae53be40f85bb4d732b799066_d.txt\", \"azureml-logs/65_job_prep-tvmps_3c776006b52538e1bbf82873aec75313d85170583b552aad04f85de9469612c1_d.txt\", \"azureml-logs/65_job_prep-tvmps_4f48c32cc392cf53c9b9b935ed4853296dd8c748e6a124113e86cd429cd85ac5_d.txt\", \"azureml-logs/65_job_prep-tvmps_4c186eff6bb17af2b4792b8b905856f73720b78f2a08de9b4eb6397a14400d35_d.txt\", \"azureml-logs/65_job_prep-tvmps_5a026e3752c03bb5f217e2de46712cb40896a87aa84ac8b44eacbe0a0c31fb69_d.txt\", \"azureml-logs/65_job_prep-tvmps_5e425782132c9db391c72bc831dbea7918d03e8e7c00b6983f3a2ca195410654_d.txt\", \"azureml-logs/65_job_prep-tvmps_6b1cc718c25aa60f2fc15815d380b99f4741217140899901920f85d8537ccf2f_d.txt\", \"azureml-logs/65_job_prep-tvmps_6bb3b15f6b598e71bd77d8732bcc408fc82b755f244ff6a1e6e001b410c13978_d.txt\", \"azureml-logs/65_job_prep-tvmps_dcf6c9433e3d34089c934cfeae8a4fdcff0716dd362ab5e6ac18ad98213e86b9_d.txt\", \"azureml-logs/65_job_prep-tvmps_a6fc3193127709481981a6b6f66391ff8ab7e12207973b6ac05f966db4e9c154_d.txt\", \"azureml-logs/65_job_prep-tvmps_7ff7e4c00de017e154d8d85601cbade5149c86caeae57624dd279b45b4573c21_d.txt\", \"azureml-logs/65_job_prep-tvmps_08ba4fc2564c12e743f9c7ee0d5ee30f59f2b026d795f29cd0148f1b1d70780f_d.txt\", \"azureml-logs/65_job_prep-tvmps_8c6d161a5ac2c3239e0d4e8aa6177d481844a9abcf438544e20dcf2854ffa046_d.txt\", \"azureml-logs/65_job_prep-tvmps_fcccfb8cfeeeb814ff46dc0121d18a3a1dd372ad2da4993c5bb1e1afa33a06ed_d.txt\", \"azureml-logs/65_job_prep-tvmps_8c7193ddaf89ee140a1770abed03537598705ff274c364d72af6240a4e2222c1_d.txt\", \"azureml-logs/65_job_prep-tvmps_bebf30f144e35d950b17b121a346f4104ba39ed8d2890327b260092b8d777e8f_d.txt\", \"azureml-logs/65_job_prep-tvmps_e42dd5967f31fd649d74245073b382f18bed0f445e0712a72c6b78cf3ea31030_d.txt\", \"azureml-logs/65_job_prep-tvmps_44f2233f2aafccc8182330cb3e3ba7ec642ef8e8e55074ed484cde6b1ae103ab_d.txt\", \"azureml-logs/65_job_prep-tvmps_63d543ababd6b9084721612575add1fb768d3358445bac67ac4f86373850782a_d.txt\", \"azureml-logs/65_job_prep-tvmps_c68e58265021296049e3857bd56b1ec05b7f1885493c92fc13d0cfd4fc5d1bd9_d.txt\", \"azureml-logs/65_job_prep-tvmps_82f7f8a698273a77771fab8ec470d9bfd1ee58cbf7342f9a4ab92b897fc889e6_d.txt\", \"azureml-logs/65_job_prep-tvmps_87de78b3cd1df0a548db449a964fcd4397be889f3a1961f05a852b673a985ac9_d.txt\", \"azureml-logs/65_job_prep-tvmps_adfe188c01c849eb17cdf486445da78a3830b75a87931141af44e4e757bf480b_d.txt\", \"azureml-logs/65_job_prep-tvmps_840c29749640ef28a43490ca9000539fc840db38a10ebcd588733a9271a18afa_d.txt\", \"azureml-logs/65_job_prep-tvmps_879d4c33ffeb0e1f1c01c91be9b59f52c1a1d5cc5d8ed94d6627479c237bff6b_d.txt\", \"azureml-logs/65_job_prep-tvmps_e886e5978634d1e3de6db014b7e59be2381966fd81f20167b7815eb01b117ec7_d.txt\", \"azureml-logs/65_job_prep-tvmps_1659e1dace2241c029d647263ff2a51ede9d9c003bdf45673109c8c81b00ee24_d.txt\", \"azureml-logs/65_job_prep-tvmps_6135c404470e13355d7db3c969d654994f703d069ea0e7f48ffd9f92bae4e482_d.txt\", \"azureml-logs/65_job_prep-tvmps_b7821eaaf0d3c2a998c60c7d9a9e515e0532ee6725e6f13f6e7da24b8eb92737_d.txt\", \"azureml-logs/65_job_prep-tvmps_9490d2700178b9884b7bfebfcbc162742d64c653c54cf79aaf845830bd72d98c_d.txt\", \"azureml-logs/65_job_prep-tvmps_45923ec3e66caf3836f5ceb45f46dce08331b2f6eeee46fdb8c6f414734a4f10_d.txt\", \"azureml-logs/65_job_prep-tvmps_56909ad7ba38d2863642af25f101df34d3c1a4487618f53e0dc997238c6c1f02_d.txt\", \"azureml-logs/65_job_prep-tvmps_d65600ea0511e4610e38766c17f55bc518013770b0b1a0f8893239ef06440501_d.txt\", \"azureml-logs/65_job_prep-tvmps_71347e775dd8fd5223e5b2492573825d87d5b1b7dc9c2c269cd6df55ae77886e_d.txt\", \"azureml-logs/65_job_prep-tvmps_df523981408e4635f0a9965c17e4521a1452c18cd123625ba669717459664c44_d.txt\"], [\"azureml-logs/70_driver_log_0.txt\", \"azureml-logs/70_driver_log_1.txt\", \"azureml-logs/70_driver_log_2.txt\", \"azureml-logs/70_driver_log_10.txt\", \"azureml-logs/70_driver_log_11.txt\", \"azureml-logs/70_driver_log_12.txt\", \"azureml-logs/70_driver_log_13.txt\", \"azureml-logs/70_driver_log_14.txt\", \"azureml-logs/70_driver_log_15.txt\", \"azureml-logs/70_driver_log_16.txt\", \"azureml-logs/70_driver_log_17.txt\", \"azureml-logs/70_driver_log_18.txt\", \"azureml-logs/70_driver_log_19.txt\", \"azureml-logs/70_driver_log_20.txt\", \"azureml-logs/70_driver_log_21.txt\", \"azureml-logs/70_driver_log_22.txt\", \"azureml-logs/70_driver_log_23.txt\", \"azureml-logs/70_driver_log_24.txt\", \"azureml-logs/70_driver_log_25.txt\", \"azureml-logs/70_driver_log_26.txt\"]], \"run_duration\": \"0:26:15\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"headnode\", \"run_id\": \"dask-xgboost_1578872294_ecf303d5\", \"categories\": [0], \"series\": [{\"data\": [\"10.2.0.5\"]}]}, {\"name\": \"scheduler\", \"run_id\": \"dask-xgboost_1578872294_ecf303d5\", \"categories\": [0], \"series\": [{\"data\": [\"10.2.0.5:8786\"]}]}, {\"name\": \"dashboard\", \"run_id\": \"dask-xgboost_1578872294_ecf303d5\", \"categories\": [0], \"series\": [{\"data\": [\"10.2.0.5:8787\"]}]}, {\"name\": \"datastore\", \"run_id\": \"dask-xgboost_1578872294_ecf303d5\", \"categories\": [0], \"series\": [{\"data\": [null]}]}], \"run_logs\": \"This is an MPI job. Rank:0\\nStarting the daemon thread to refresh tokens in background for process with pid = 217\\nEntering Run History Context Manager.\\n/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/notebook/notebookapp.py:48: DeprecationWarning: zmq.eventloop.ioloop is deprecated in pyzmq 17. pyzmq now works with default tornado and asyncio eventloops.\\n  ioloop.install()\\n- my rank is  0\\n- my ip is  10.2.0.5\\n- scheduler is  10.2.0.5:8786\\n- dashboard is  10.2.0.5:8787\\nargs:  Namespace(datastore=None, jupyter=False, jupyter_token='0cf97842359611eaae0f000d3a60d4d5', script=None)\\nunparsed:  []\\n- my rank is  0\\n- my ip is  10.2.0.5\\ndistributed.scheduler - INFO - -----------------------------------------------\\ndistributed.nanny - INFO -         Start Nanny at: 'tcp://10.2.0.5:37965'\\ndistributed.scheduler - INFO - Local Directory:    /tmp/scheduler-3c07gkia\\ndistributed.scheduler - INFO - -----------------------------------------------\\ndistributed.scheduler - INFO - Clear task state\\ndistributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: pip install jupyter-server-proxy\\ndistributed.scheduler - INFO -   Scheduler at:       tcp://10.2.0.5:8786\\ndistributed.scheduler - INFO -   dashboard at:                     :8787\\ndistributed.scheduler - INFO - Register tcp://10.2.0.30:45931\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.30:45931\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.42:38649\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.42:38649\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.18:41879\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.18:41879\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.44:34667\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.44:34667\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.41:41247\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.41:41247\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.26:43119\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.26:43119\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.14:43591\\ndistributed.scheduler - INFO - Register tcp://10.2.0.17:36329\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.14:43591\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.17:36329\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.21:35801\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.21:35801\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.35:35577\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.35:35577\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.9:38245\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.9:38245\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.24:32853\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.24:32853\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.12:46723\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.12:46723\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.8:37925\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.8:37925\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.27:35191\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.27:35191\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.46:34013\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.46:34013\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.6:39305\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.6:39305\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.33:42887\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.33:42887\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.36:44685\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.36:44685\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.37:40909\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.37:40909\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.29:36769\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.29:36769\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.22:39413\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.22:39413\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.45:45037\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.45:45037\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.10:44245\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.10:44245\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.25:44245\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.25:44245\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.39:37673\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.39:37673\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.32:38725\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.32:38725\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.7:41897\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.7:41897\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.31:33545\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.31:33545\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.43:38033\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.43:38033\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.40:42973\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.40:42973\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.34:32779\\ndistributed.scheduler - INFO - Register tcp://10.2.0.23:44597\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.34:32779\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.23:44597\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.19:44949\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.19:44949\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.20:32877\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.20:32877\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.38:37749\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.38:37749\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.28:37847\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.28:37847\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.13:40123\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.13:40123\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.11:38945\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.11:38945\\ndistributed.core - INFO - Starting established connection\\ndistributed.worker - INFO -       Start worker at:       tcp://10.2.0.5:36175\\ndistributed.worker - INFO -          Listening to:       tcp://10.2.0.5:36175\\ndistributed.worker - INFO -          dashboard at:             10.2.0.5:45737\\ndistributed.worker - INFO - Waiting to connect to:        tcp://10.2.0.5:8786\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.worker - INFO -               Threads:                         16\\ndistributed.worker - INFO -                Memory:                  118.27 GB\\ndistributed.worker - INFO -       Local Directory: /mnt/batch/tasks/shared/LS_root/jobs/ncus-azureml/azureml/dask-xgboost_1578872294_ecf303d5/mounts/workspaceblobstore/azureml/dask-xgboost_1578872294_ecf303d5/worker-_6q3bmbr\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.scheduler - INFO - Register tcp://10.2.0.5:36175\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.5:36175\\ndistributed.worker - INFO -         Registered to:        tcp://10.2.0.5:8786\\ndistributed.core - INFO - Starting established connection\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Receive client connection: Client-2544a81a-3596-11ea-bab0-000d3a3c66ed\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Send lost future signal to clients\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.10:44245\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.10:44245\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.11:38945\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.11:38945\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.12:46723\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.12:46723\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.13:40123\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.13:40123\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.14:43591\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.14:43591\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.17:36329\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.17:36329\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.18:41879\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.18:41879\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.19:44949\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.19:44949\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.20:32877\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.20:32877\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.21:35801\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.21:35801\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.22:39413\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.22:39413\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.23:44597\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.23:44597\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.24:32853\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.24:32853\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.25:44245\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.25:44245\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.26:43119\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.26:43119\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.27:35191\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.27:35191\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.28:37847\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.28:37847\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.29:36769\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.29:36769\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.30:45931\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.30:45931\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.31:33545\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.31:33545\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.32:38725\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.32:38725\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.33:42887\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.33:42887\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.34:32779\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.34:32779\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.35:35577\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.35:35577\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.36:44685\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.36:44685\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.37:40909\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.37:40909\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.38:37749\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.38:37749\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.39:37673\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.39:37673\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.40:42973\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.40:42973\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.41:41247\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.41:41247\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.42:38649\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.42:38649\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.43:38033\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.43:38033\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.44:34667\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.44:34667\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.45:45037\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.45:45037\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.46:34013\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.46:34013\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.5:36175\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.5:36175\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.6:39305\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.6:39305\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.7:41897\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.7:41897\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.8:37925\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.8:37925\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.9:38245\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.9:38245\\ndistributed.scheduler - INFO - Lost all workers\\ndistributed.scheduler - INFO - Clear task state\\ndistributed.scheduler - INFO - Register tcp://10.2.0.33:42887\\ndistributed.scheduler - INFO - Register tcp://10.2.0.36:44685\\ndistributed.scheduler - INFO - Register tcp://10.2.0.37:40909\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.33:42887\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.29:36769\\ndistributed.scheduler - INFO - Register tcp://10.2.0.22:39413\\ndistributed.scheduler - INFO - Register tcp://10.2.0.45:45037\\ndistributed.worker - INFO - Stopping worker at tcp://10.2.0.5:36175\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.36:44685\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.37:40909\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.29:36769\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.22:39413\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.45:45037\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.22:39413\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.22:39413\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.36:44685\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.36:44685\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.29:36769\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.29:36769\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.45:45037\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.45:45037\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.33:42887\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.33:42887\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.37:40909\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.37:40909\\ndistributed.scheduler - INFO - Lost all workers\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer\\ndistributed.nanny - WARNING - Restarting worker\\ndistributed.scheduler - INFO - Register tcp://10.2.0.12:42039\\ndistributed.scheduler - INFO - Register tcp://10.2.0.14:42523\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.12:42039\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.14:42523\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.21:37851\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.21:37851\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.18:39995\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.18:39995\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.24:43203\\ndistributed.scheduler - INFO - Register tcp://10.2.0.44:41621\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.24:43203\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.44:41621\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.19:42795\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.19:42795\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.30:44553\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.30:44553\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.25:34229\\ndistributed.scheduler - INFO - Register tcp://10.2.0.27:35045\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.25:34229\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.27:35045\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.13:34737\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.13:34737\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.26:36069\\ndistributed.scheduler - INFO - Register tcp://10.2.0.22:34321\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.26:36069\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.22:34321\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.17:42021\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.17:42021\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.23:35473\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.23:35473\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.20:37929\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.20:37929\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.11:41579\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.11:41579\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.43:41105\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.43:41105\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.42:36125\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.42:36125\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.10:41751\\ndistributed.scheduler - INFO - Register tcp://10.2.0.9:42929\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.10:41751\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.9:42929\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.35:43711\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.35:43711\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.33:38741\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.33:38741\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.29:33853\\ndistributed.scheduler - INFO - Register tcp://10.2.0.40:43165\\ndistributed.scheduler - INFO - Register tcp://10.2.0.8:38871\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.29:33853\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.40:43165\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.8:38871\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.46:44295\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.46:44295\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.7:38249\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.7:38249\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.41:39905\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.41:39905\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.37:43023\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.37:43023\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.45:43325\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.45:43325\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.32:33489\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.32:33489\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.36:33827\\ndistributed.scheduler - INFO - Register tcp://10.2.0.31:34791\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.36:33827\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.31:34791\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.34:42909\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.34:42909\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.28:39581\\ndistributed.scheduler - INFO - Register tcp://10.2.0.6:34509\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.28:39581\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.6:34509\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.38:45783\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.38:45783\\ndistributed.core - INFO - Starting established connection\\ndistributed.worker - INFO -       Start worker at:       tcp://10.2.0.5:37251\\ndistributed.worker - INFO -          Listening to:       tcp://10.2.0.5:37251\\ndistributed.worker - INFO -          dashboard at:             10.2.0.5:43601\\ndistributed.worker - INFO - Waiting to connect to:        tcp://10.2.0.5:8786\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.worker - INFO -               Threads:                         16\\ndistributed.worker - INFO -                Memory:                  118.27 GB\\ndistributed.worker - INFO -       Local Directory: /mnt/batch/tasks/shared/LS_root/jobs/ncus-azureml/azureml/dask-xgboost_1578872294_ecf303d5/mounts/workspaceblobstore/azureml/dask-xgboost_1578872294_ecf303d5/worker-yjgub2c_\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.scheduler - INFO - Register tcp://10.2.0.5:37251\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.5:37251\\ndistributed.core - INFO - Starting established connection\\ndistributed.worker - INFO -         Registered to:        tcp://10.2.0.5:8786\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.39:33037\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.39:33037\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Clear task state\\ndistributed.scheduler - INFO - Remove client Client-2544a81a-3596-11ea-bab0-000d3a3c66ed\\ndistributed.scheduler - INFO - Close client connection: Client-2544a81a-3596-11ea-bab0-000d3a3c66ed\\ndistributed.scheduler - INFO - Receive client connection: Client-b50e1da4-3596-11ea-9580-000d3a3c66ed\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Send lost future signal to clients\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.10:41751\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.10:41751\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.11:41579\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.11:41579\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.12:42039\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.12:42039\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.13:34737\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.13:34737\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.14:42523\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.14:42523\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.17:42021\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.17:42021\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.18:39995\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.18:39995\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.19:42795\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.19:42795\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.20:37929\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.20:37929\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.21:37851\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.21:37851\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.22:34321\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.22:34321\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.23:35473\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.23:35473\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.24:43203\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.24:43203\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.25:34229\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.25:34229\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.26:36069\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.26:36069\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.27:35045\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.27:35045\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.28:39581\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.28:39581\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.29:33853\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.29:33853\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.30:44553\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.30:44553\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.31:34791\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.31:34791\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.32:33489\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.32:33489\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.33:38741\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.33:38741\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.34:42909\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.34:42909\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.35:43711\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.35:43711\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.36:33827\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.36:33827\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.37:43023\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.37:43023\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.38:45783\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.38:45783\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.39:33037\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.39:33037\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.40:43165\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.40:43165\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.41:39905\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.41:39905\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.42:36125\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.42:36125\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.43:41105\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.43:41105\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.44:41621\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.44:41621\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.45:43325\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.45:43325\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.46:44295\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.46:44295\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.5:37251\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.5:37251\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.6:34509\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.6:34509\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.7:38249\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.7:38249\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.8:38871\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.8:38871\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.9:42929\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.9:42929\\ndistributed.scheduler - INFO - Lost all workers\\ndistributed.scheduler - INFO - Clear task state\\ndistributed.scheduler - INFO - Register tcp://10.2.0.9:42929\\ndistributed.scheduler - INFO - Register tcp://10.2.0.10:41751\\ndistributed.scheduler - INFO - Register tcp://10.2.0.35:43711\\ndistributed.scheduler - INFO - Register tcp://10.2.0.33:38741\\ndistributed.scheduler - INFO - Register tcp://10.2.0.8:38871\\ndistributed.scheduler - INFO - Register tcp://10.2.0.29:33853\\ndistributed.scheduler - INFO - Register tcp://10.2.0.40:43165\\ndistributed.worker - INFO - Stopping worker at tcp://10.2.0.5:37251\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.9:42929\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.10:41751\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.35:43711\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.33:38741\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.46:44295\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.8:38871\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.29:33853\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.40:43165\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.46:44295\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.35:43711\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.35:43711\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.10:41751\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.10:41751\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.29:33853\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.29:33853\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.40:43165\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.40:43165\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.33:38741\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.33:38741\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.8:38871\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.8:38871\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.9:42929\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.9:42929\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: ConnectionResetError: [Errno 104] Connection reset by peer\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.46:44295\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.46:44295\\ndistributed.scheduler - INFO - Lost all workers\\ndistributed.scheduler - INFO - Register tcp://10.2.0.21:42337\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.21:42337\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.17:37545\\ndistributed.scheduler - INFO - Register tcp://10.2.0.18:40539\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.17:37545\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.44:38063\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.18:40539\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.44:38063\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.33:39413\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.33:39413\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.35:44683\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.35:44683\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.41:41673\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.41:41673\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.42:33651\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.42:33651\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.11:35365\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.11:35365\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.27:38289\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.27:38289\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.10:34465\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.10:34465\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.8:38963\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.8:38963\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.24:45185\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.24:45185\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.43:42003\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.43:42003\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.19:35447\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.19:35447\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.25:36359\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.25:36359\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.9:37653\\ndistributed.scheduler - INFO - Register tcp://10.2.0.23:34679\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.9:37653\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.23:34679\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.46:33945\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.46:33945\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.30:44499\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.30:44499\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.12:45511\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.12:45511\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.32:41815\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.32:41815\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.7:34619\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.7:34619\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.26:38687\\ndistributed.scheduler - INFO - Register tcp://10.2.0.37:33723\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.26:38687\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.37:33723\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.6:37791\\ndistributed.scheduler - INFO - Register tcp://10.2.0.13:46307\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.6:37791\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.13:46307\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.45:45855\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.45:45855\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.14:35141\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.14:35141\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.29:33085\\ndistributed.scheduler - INFO - Register tcp://10.2.0.38:42287\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.29:33085\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.38:42287\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.39:40645\\ndistributed.worker - INFO -       Start worker at:       tcp://10.2.0.5:33203\\ndistributed.worker - INFO -          Listening to:       tcp://10.2.0.5:33203\\ndistributed.worker - INFO -          dashboard at:             10.2.0.5:43303\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.39:40645\\ndistributed.worker - INFO - Waiting to connect to:        tcp://10.2.0.5:8786\\ndistributed.core - INFO - Starting established connection\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.worker - INFO -               Threads:                         16\\ndistributed.worker - INFO -                Memory:                  118.27 GB\\ndistributed.worker - INFO -       Local Directory: /mnt/batch/tasks/shared/LS_root/jobs/ncus-azureml/azureml/dask-xgboost_1578872294_ecf303d5/mounts/workspaceblobstore/azureml/dask-xgboost_1578872294_ecf303d5/worker-o01_levr\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.scheduler - INFO - Register tcp://10.2.0.5:33203\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.5:33203\\ndistributed.core - INFO - Starting established connection\\ndistributed.worker - INFO -         Registered to:        tcp://10.2.0.5:8786\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.40:42961\\ndistributed.scheduler - INFO - Register tcp://10.2.0.22:40181\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.40:42961\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.22:40181\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.31:42135\\ndistributed.scheduler - INFO - Register tcp://10.2.0.28:45083\\ndistributed.scheduler - INFO - Register tcp://10.2.0.20:42005\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.31:42135\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.28:45083\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.20:42005\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.34:44701\\ndistributed.scheduler - INFO - Register tcp://10.2.0.36:36065\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.34:44701\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.36:36065\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Clear task state\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.10:34465\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.10:34465\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.scheduler - INFO - Register tcp://10.2.0.10:34465\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.10:34465\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.26:38687\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.26:38687\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.30:44499\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.30:44499\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.42:33651\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.42:33651\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.17:37545\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.17:37545\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.24:45185\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.24:45185\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.14:35141\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.14:35141\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.41:41673\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.41:41673\\ndistributed.scheduler - INFO - Register tcp://10.2.0.26:38687\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.9:37653\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.9:37653\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.37:33723\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.37:33723\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.12:45511\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.12:45511\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.40:42961\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.40:42961\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.22:40181\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.22:40181\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.27:38289\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.27:38289\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.28:45083\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.28:45083\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.43:42003\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.43:42003\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.44:38063\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.44:38063\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.8:38963\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.8:38963\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.33:39413\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.33:39413\\ndistributed.protocol.pickle - INFO - Failed to deserialize b\\\"\\\\x80\\\\x04\\\\x952\\\\x11\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00(\\\\x8c\\\\x11dask.optimization\\\\x94\\\\x8c\\\\x10SubgraphCallable\\\\x94\\\\x93\\\\x94(}\\\\x94(\\\\x8c5drop_by_shallow_copy-1eb436d2f3f3dd0da551a68fdf080bb9\\\\x94(\\\\x8c\\\\ndask.utils\\\\x94\\\\x8c\\\\x05apply\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x13dask.dataframe.core\\\\x94\\\\x8c\\\\x11apply_and_enforce\\\\x94\\\\x93\\\\x94]\\\\x94(\\\\x8c'assign-9f1ed1acabd87b3d85213034009616f4\\\\x94\\\\x8c\\\\x02_0\\\\x94e\\\\x8c\\\\x08builtins\\\\x94\\\\x8c\\\\x04dict\\\\x94\\\\x93\\\\x94]\\\\x94(]\\\\x94(\\\\x8c\\\\x05_func\\\\x94\\\\x8c\\\\x14dask.dataframe.utils\\\\x94\\\\x8c\\\\x14drop_by_shallow_copy\\\\x94\\\\x93\\\\x94e]\\\\x94(\\\\x8c\\\\x05_meta\\\\x94\\\\x8c\\\\x11pandas.core.frame\\\\x94\\\\x8c\\\\tDataFrame\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94(\\\\x8c\\\\x05_data\\\\x94\\\\x8c\\\\x15pandas.core.internals\\\\x94\\\\x8c\\\\x0cBlockManager\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94(]\\\\x94(\\\\x8c\\\\x18pandas.core.indexes.base\\\\x94\\\\x8c\\\\n_new_Index\\\\x94\\\\x93\\\\x94h$\\\\x8c\\\\x05Index\\\\x94\\\\x93\\\\x94}\\\\x94(\\\\x8c\\\\x04data\\\\x94\\\\x8c\\\\x15numpy.core.multiarray\\\\x94\\\\x8c\\\\x0c_reconstruct\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x05numpy\\\\x94\\\\x8c\\\\x07ndarray\\\\x94\\\\x93\\\\x94K\\\\x00\\\\x85\\\\x94C\\\\x01b\\\\x94\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x14\\\\x85\\\\x94h.\\\\x8c\\\\x05dtype\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x02O8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03\\\\x8c\\\\x01|\\\\x94NNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK?t\\\\x94b\\\\x89]\\\\x94(\\\\x8c\\\\x04usaf\\\\x94\\\\x8c\\\\x04wban\\\\x94\\\\x8c\\\\x08latitude\\\\x94\\\\x8c\\\\tlongitude\\\\x94\\\\x8c\\\\televation\\\\x94\\\\x8c\\\\twindAngle\\\\x94\\\\x8c\\\\twindSpeed\\\\x94\\\\x8c\\\\x0eseaLvlPressure\\\\x94\\\\x8c\\\\rcloudCoverage\\\\x94\\\\x8c\\\\x17presentWeatherIndicator\\\\x94\\\\x8c\\\\x14pastWeatherIndicator\\\\x94\\\\x8c\\\\nprecipTime\\\\x94\\\\x8c\\\\x0bprecipDepth\\\\x94\\\\x8c\\\\tsnowDepth\\\\x94\\\\x8c\\\\x0bstationName\\\\x94\\\\x8c\\\\x0fcountryOrRegion\\\\x94\\\\x8c\\\\x03p_k\\\\x94\\\\x8c\\\\x04year\\\\x94\\\\x8c\\\\x03day\\\\x94\\\\x8c\\\\x05month\\\\x94et\\\\x94b\\\\x8c\\\\x04name\\\\x94Nu\\\\x86\\\\x94R\\\\x94h&\\\\x8c\\\\x19pandas.core.indexes.range\\\\x94\\\\x8c\\\\nRangeIndex\\\\x94\\\\x93\\\\x94}\\\\x94(hSN\\\\x8c\\\\x05start\\\\x94K\\\\x00\\\\x8c\\\\x04stop\\\\x94K\\\\x00\\\\x8c\\\\x04step\\\\x94K\\\\x01u\\\\x86\\\\x94R\\\\x94e]\\\\x94(h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06K\\\\x00\\\\x86\\\\x94h:\\\\x89]\\\\x94t\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x08K\\\\x00\\\\x86\\\\x94h7\\\\x8c\\\\x02f8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03\\\\x8c\\\\x01<\\\\x94NNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK\\\\x00t\\\\x94b\\\\x89C\\\\x00\\\\x94t\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05K\\\\x00\\\\x86\\\\x94h7\\\\x8c\\\\x02i4\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03hmNNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK\\\\x00t\\\\x94b\\\\x89hot\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x01K\\\\x00\\\\x86\\\\x94h7\\\\x8c\\\\x02i8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03hmNNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK\\\\x00t\\\\x94b\\\\x89hot\\\\x94be]\\\\x94(h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06\\\\x85\\\\x94h:\\\\x89]\\\\x94(h>h?hFhLhMhNet\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x08\\\\x85\\\\x94h:\\\\x89]\\\\x94(h@hAhBhDhEhIhJhKet\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05\\\\x85\\\\x94h:\\\\x89]\\\\x94(hChGhHhOhPet\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x01\\\\x85\\\\x94h:\\\\x89]\\\\x94hQat\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94e}\\\\x94\\\\x8c\\\\x060.14.1\\\\x94}\\\\x94(\\\\x8c\\\\x04axes\\\\x94h#\\\\x8c\\\\x06blocks\\\\x94]\\\\x94(}\\\\x94(\\\\x8c\\\\x06values\\\\x94hb\\\\x8c\\\\x08mgr_locs\\\\x94h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06\\\\x85\\\\x94h\\\\x80\\\\x89C0\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x01\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x08\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0e\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0f\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x10\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bu}\\\\x94(h\\\\xafhhh\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x08\\\\x85\\\\x94h\\\\x80\\\\x89C@\\\\x02\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x03\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x04\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x06\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x07\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0b\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0c\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\r\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bu}\\\\x94(h\\\\xafhsh\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05\\\\x85\\\\x94h\\\\x80\\\\x89C(\\\\x05\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\t\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\n\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x11\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x12\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bu}\\\\x94(h\\\\xafh|h\\\\xb0h\\\\x0e\\\\x8c\\\\x05slice\\\\x94\\\\x93\\\\x94K\\\\x13K\\\\x14K\\\\x01\\\\x87\\\\x94R\\\\x94ueust\\\\x94b\\\\x8c\\\\x04_typ\\\\x94\\\\x8c\\\\tdataframe\\\\x94\\\\x8c\\\\t_metadata\\\\x94]\\\\x94ube]\\\\x94(\\\\x8c\\\\x06errors\\\\x94\\\\x8c\\\\x05raise\\\\x94ee\\\\x86\\\\x94t\\\\x94h\\\\x0c(\\\\x8c\\\\x16dask.dataframe.methods\\\\x94\\\\x8c\\\\x06assign\\\\x94\\\\x93\\\\x94\\\\x8c'fillna-ad2330fa66156eef706e40f6ea22a8f6\\\\x94\\\\x8c\\\\x02_2\\\\x94\\\\x8c)dt-month-fd72f74d58f2de24ac49ed67e72c552a\\\\x94t\\\\x94h\\\\xd9(h\\\\x07h\\\\n]\\\\x94(\\\\x8c(getitem-f5ed0cddf246d10aa558103ce515cd9a\\\\x94\\\\x8c\\\\x02_3\\\\x94h\\\\xd8eh\\\\x10]\\\\x94(]\\\\x94(h\\\\x13\\\\x8c\\\\x17dask.dataframe.accessor\\\\x94\\\\x8c\\\\x1bAccessor._delegate_property\\\\x94\\\\x93\\\\x94e]\\\\x94(h\\\\x18\\\\x8c\\\\x12pandas.core.series\\\\x94\\\\x8c\\\\x06Series\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94(h\\\\x1eh\\\\x1f\\\\x8c\\\\x12SingleBlockManager\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94(]\\\\x94h&hX}\\\\x94(hSNhZK\\\\x00h[K\\\\x00h\\\\\\\\K\\\\x01u\\\\x86\\\\x94R\\\\x94a]\\\\x94h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x00\\\\x85\\\\x94h\\\\x80\\\\x89hot\\\\x94ba]\\\\x94h&\\\\x8c\\\\x1bpandas.core.indexes.numeric\\\\x94\\\\x8c\\\\nInt64Index\\\\x94\\\\x93\\\\x94}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x00\\\\x85\\\\x94h\\\\x80\\\\x89hot\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94a}\\\\x94h\\\\xa9}\\\\x94(h\\\\xabh\\\\xech\\\\xac]\\\\x94}\\\\x94(h\\\\xafh\\\\xf3h\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x00\\\\x85\\\\x94h\\\\x80\\\\x89hot\\\\x94buaust\\\\x94bh\\\\xcb\\\\x8c\\\\x06series\\\\x94h\\\\xcd]\\\\x94hSahS\\\\x8c\\\\x08datetime\\\\x94ubee\\\\x86\\\\x94t\\\\x94h\\\\xdc\\\\x8c\\\\t_operator\\\\x94\\\\x8c\\\\x07getitem\\\\x94\\\\x93\\\\x94h\\\\xd7\\\\x8c\\\\x02_5\\\\x94\\\\x87\\\\x94h\\\\xd7(h\\\\x07h\\\\x05\\\\x8c\\\\x0cmethodcaller\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x06fillna\\\\x94\\\\x85\\\\x94R\\\\x94]\\\\x94(\\\\x8c\\\\x02_6\\\\x94\\\\x8c\\\\x02_7\\\\x94eh\\\\x10]\\\\x94(]\\\\x94(\\\\x8c\\\\x06method\\\\x94Ne]\\\\x94(\\\\x8c\\\\x05limit\\\\x94Ne]\\\\x94(\\\\x8c\\\\x04axis\\\\x94K\\\\x00ee\\\\x86\\\\x94t\\\\x94uh\\\\x04(\\\\x8c\\\\x02_0\\\\x94\\\\x8c\\\\x02_1\\\\x94\\\\x8c\\\\x02_2\\\\x94\\\\x8c\\\\x02_3\\\\x94\\\\x8c\\\\x02_4\\\\x94\\\\x8c\\\\x02_5\\\\x94\\\\x8c\\\\x02_6\\\\x94\\\\x8c\\\\x02_7\\\\x94\\\\x8c\\\\x02_8\\\\x94t\\\\x94\\\\x8c\\\\x11subgraph_callable\\\\x94t\\\\x94R\\\\x94]\\\\x94(\\\\x8c\\\\x0btemperature\\\\x94\\\\x8c\\\\x08datetime\\\\x94\\\\x8c\\\\x07version\\\\x94eh\\\\x0chQ\\\\x8c\\\\x02dt\\\\x94h\\\\xdcj6\\\\x01\\\\x00\\\\x00(\\\\x8c\\\\x1edask.dataframe.io.parquet.core\\\\x94\\\\x8c\\\\x11read_parquet_part\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x1fdask.dataframe.io.parquet.arrow\\\\x94\\\\x8c\\\\x1aArrowEngine.read_partition\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x0bfsspec.spec\\\\x94\\\\x8c\\\\rmake_instance\\\\x94\\\\x93\\\\x94\\\\x8c\\\\nadlfs.core\\\\x94\\\\x8c\\\\x13AzureBlobFileSystem\\\\x94\\\\x93\\\\x94)}\\\\x94(\\\\x8c\\\\x0econtainer_name\\\\x94\\\\x8c\\\\x08datasets\\\\x94\\\\x8c\\\\x0caccount_name\\\\x94\\\\x8c\\\\tdata4dask\\\\x94\\\\x8c\\\\x0baccount_key\\\\x94\\\\x8cXmupxHTCWrYQC252cFAWCAm7lSlMPTCt5J3j7FCXIlXW/k3OIdLrWssVnMGKVX6N96XoIlw9O8PkQya3cNB9xKw==\\\\x94u\\\\x87\\\\x94R\\\\x94h\\\\x1b)\\\\x81\\\\x94}\\\\x94(h\\\\x1eh!)\\\\x81\\\\x94(]\\\\x94(h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x16\\\\x85\\\\x94h7\\\\x8c\\\\x02O8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03h;NNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK?t\\\\x94b\\\\x89]\\\\x94(h>h?j\\\\x0e\\\\x01\\\\x00\\\\x00h@hAhBhChD\\\\x8c\\\\x0btemperature\\\\x94hEhFhGhHhIhJhKhLhMhNhOhP\\\\x8c\\\\x07version\\\\x94et\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&hX}\\\\x94(hSNhZK\\\\x00h[K\\\\x00h\\\\\\\\K\\\\x01u\\\\x86\\\\x94R\\\\x94e]\\\\x94(h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06K\\\\x00\\\\x86\\\\x94jY\\\\x01\\\\x00\\\\x00\\\\x89]\\\\x94t\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x01K\\\\x00\\\\x86\\\\x94h7\\\\x8c\\\\x02M8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x04hmNNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK\\\\x00}\\\\x94(C\\\\x02ns\\\\x94K\\\\x01K\\\\x01K\\\\x01t\\\\x94\\\\x86\\\\x94t\\\\x94b\\\\x89hot\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\nK\\\\x00\\\\x86\\\\x94hl\\\\x89hot\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05K\\\\x00\\\\x86\\\\x94hw\\\\x89hot\\\\x94be]\\\\x94(h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06\\\\x85\\\\x94jY\\\\x01\\\\x00\\\\x00\\\\x89]\\\\x94(h>h?hFhLhMhNet\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x01\\\\x85\\\\x94jY\\\\x01\\\\x00\\\\x00\\\\x89]\\\\x94j\\\\x0e\\\\x01\\\\x00\\\\x00at\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\n\\\\x85\\\\x94jY\\\\x01\\\\x00\\\\x00\\\\x89]\\\\x94(h@hAhBhDj\\\\\\\\\\\\x01\\\\x00\\\\x00hEhIhJhKj]\\\\x01\\\\x00\\\\x00et\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05\\\\x85\\\\x94jY\\\\x01\\\\x00\\\\x00\\\\x89]\\\\x94(hChGhHhOhPet\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94e}\\\\x94h\\\\xa9}\\\\x94(h\\\\xabjQ\\\\x01\\\\x00\\\\x00h\\\\xac]\\\\x94(}\\\\x94(h\\\\xafjg\\\\x01\\\\x00\\\\x00h\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06\\\\x85\\\\x94h7\\\\x8c\\\\x02i8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03hmNNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK\\\\x00t\\\\x94b\\\\x89C0\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x01\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\n\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x10\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x11\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x12\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bu}\\\\x94(h\\\\xafjm\\\\x01\\\\x00\\\\x00h\\\\xb0h\\\\xc7K\\\\x02K\\\\x03K\\\\x01\\\\x87\\\\x94R\\\\x94u}\\\\x94(h\\\\xafjz\\\\x01\\\\x00\\\\x00h\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\n\\\\x85\\\\x94j\\\\xb1\\\\x01\\\\x00\\\\x00\\\\x89CP\\\\x03\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x04\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x05\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x07\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x08\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\t\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\r\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0e\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0f\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x15\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bu}\\\\x94(h\\\\xafj\\\\x7f\\\\x01\\\\x00\\\\x00h\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05\\\\x85\\\\x94j\\\\xb1\\\\x01\\\\x00\\\\x00\\\\x89C(\\\\x06\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0b\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0c\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x13\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x14\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bueust\\\\x94bh\\\\xcb\\\\x8c\\\\tdataframe\\\\x94h\\\\xcd]\\\\x94ub\\\\x8cznoaa/isd/year=2010/month=11/part-00005-tid-2760641154746282667-d6a50598-0478-455f-9217-ce4afb96a9bb-32.c000.snappy.parquet\\\\x94N]\\\\x94\\\\x87\\\\x94]\\\\x94(h>h?j\\\\x0e\\\\x01\\\\x00\\\\x00h@hAhBhChDj\\\\\\\\\\\\x01\\\\x00\\\\x00hEhFhGhHhIhJhKhLhMhNhOhPj]\\\\x01\\\\x00\\\\x00eN}\\\\x94(\\\\x8c\\\\npartitions\\\\x94N\\\\x8c\\\\ncategories\\\\x94Nut\\\\x94K\\\\x00\\\\x8c-read-parquet-988028e491775459c2507adcc3fad764\\\\x94t\\\\x94.\\\"\\nTraceback (most recent call last):\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.7:34619\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/pickle.py\\\", line 59, in loads\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.7:34619\\n    return pickle.loads(x)\\nAttributeError: Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.protocol.core - CRITICAL - Failed to deserialize\\nTraceback (most recent call last):\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/core.py\\\", line 124, in loads\\n    value = _deserialize(head, fs, deserializers=deserializers)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 268, in deserialize\\n    return loads(header, frames)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 62, in pickle_loads\\n    return pickle.loads(b\\\"\\\".join(frames))\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/pickle.py\\\", line 59, in loads\\n    return pickle.loads(x)\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.39:40645\\nAttributeError: Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.39:40645\\ndistributed.core - ERROR - Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\nTraceback (most recent call last):\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/core.py\\\", line 447, in handle_stream\\n    msgs = await comm.read()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/tcp.py\\\", line 208, in read\\n    frames, deserialize=self.deserialize, deserializers=deserializers\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/tornado/gen.py\\\", line 209, in wrapper\\n    yielded = next(result)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 66, in from_frames\\n    res = _from_frames()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 52, in _from_frames\\n    frames, deserialize=deserialize, deserializers=deserializers\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/core.py\\\", line 124, in loads\\n    value = _deserialize(head, fs, deserializers=deserializers)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 268, in deserialize\\n    return loads(header, frames)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 62, in pickle_loads\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.35:44683\\n    return pickle.loads(b\\\"\\\".join(frames))\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.35:44683\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/pickle.py\\\", line 59, in loads\\n    return pickle.loads(x)\\nAttributeError: Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.worker - ERROR - Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\nTraceback (most recent call last):\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/worker.py\\\", line 904, in handle_scheduler\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.36:36065\\n    comm, every_cycle=[self.ensure_communicating, self.ensure_computing]\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.36:36065\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/core.py\\\", line 447, in handle_stream\\n    msgs = await comm.read()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/tcp.py\\\", line 208, in read\\n    frames, deserialize=self.deserialize, deserializers=deserializers\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/tornado/gen.py\\\", line 209, in wrapper\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\n    yielded = next(result)\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.38:42287\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 66, in from_frames\\n    res = _from_frames()\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.38:42287\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 52, in _from_frames\\n    frames, deserialize=deserialize, deserializers=deserializers\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/core.py\\\", line 124, in loads\\n    value = _deserialize(head, fs, deserializers=deserializers)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 268, in deserialize\\n    return loads(header, frames)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 62, in pickle_loads\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\n    return pickle.loads(b\\\"\\\".join(frames))\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/pickle.py\\\", line 59, in loads\\n    return pickle.loads(x)\\nAttributeError: Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\\ntornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f3778a3b588>>, <Task finished coro=<Worker.handle_scheduler() done, defined at /azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/worker.py:901> exception=AttributeError(\\\"Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\\",)>)\\nTraceback (most recent call last):\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/tornado/ioloop.py\\\", line 743, in _run_callback\\n    ret = callback()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/tornado/ioloop.py\\\", line 767, in _discard_future_result\\n    future.result()\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.46:33945\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/worker.py\\\", line 904, in handle_scheduler\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.46:33945\\n    comm, every_cycle=[self.ensure_communicating, self.ensure_computing]\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/core.py\\\", line 447, in handle_stream\\n    msgs = await comm.read()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/tcp.py\\\", line 208, in read\\n    frames, deserialize=self.deserialize, deserializers=deserializers\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/tornado/gen.py\\\", line 209, in wrapper\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.45:45855\\n    yielded = next(result)\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.45:45855\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 66, in from_frames\\n    res = _from_frames()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 52, in _from_frames\\n    frames, deserialize=deserialize, deserializers=deserializers\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/core.py\\\", line 124, in loads\\n    value = _deserialize(head, fs, deserializers=deserializers)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 268, in deserialize\\n    return loads(header, frames)\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.23:34679\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 62, in pickle_loads\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.23:34679\\n    return pickle.loads(b\\\"\\\".join(frames))\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/pickle.py\\\", line 59, in loads\\n    return pickle.loads(x)\\nAttributeError: Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.31:42135\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.31:42135\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.25:36359\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.25:36359\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.32:41815\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.32:41815\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.29:33085\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.29:33085\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.18:40539\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.18:40539\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.26:38687\\ndistributed.core - INFO - Starting established connection\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.20:42005\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.20:42005\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.13:46307\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.13:46307\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.19:35447\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.19:35447\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.5:33203\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.5:33203\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.6:37791\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.6:37791\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.scheduler - INFO - Register tcp://10.2.0.30:44499\\ndistributed.scheduler - INFO - Register tcp://10.2.0.24:45185\\ndistributed.scheduler - INFO - Register tcp://10.2.0.14:35141\\ndistributed.scheduler - INFO - Register tcp://10.2.0.9:37653\\ndistributed.scheduler - INFO - Register tcp://10.2.0.41:41673\\ndistributed.scheduler - INFO - Register tcp://10.2.0.42:33651\\ndistributed.scheduler - INFO - Register tcp://10.2.0.37:33723\\ndistributed.scheduler - INFO - Register tcp://10.2.0.17:37545\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.21:42337\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.21:42337\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.11:35365\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.11:35365\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.34:44701\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.34:44701\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.scheduler - INFO - Register tcp://10.2.0.12:45511\\ndistributed.scheduler - INFO - Register tcp://10.2.0.8:38963\\ndistributed.scheduler - INFO - Register tcp://10.2.0.43:42003\\ndistributed.scheduler - INFO - Register tcp://10.2.0.44:38063\\ndistributed.scheduler - INFO - Register tcp://10.2.0.27:38289\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.30:44499\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.24:45185\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.14:35141\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.9:37653\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.41:41673\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.42:33651\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.37:33723\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.17:37545\\ndistributed.core - INFO - Starting established connection\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.scheduler - INFO - Register tcp://10.2.0.33:39413\\ndistributed.scheduler - INFO - Register tcp://10.2.0.39:40645\\ndistributed.scheduler - INFO - Register tcp://10.2.0.45:45855\\ndistributed.scheduler - INFO - Register tcp://10.2.0.23:34679\\ndistributed.scheduler - INFO - Register tcp://10.2.0.7:34619\\ndistributed.scheduler - INFO - Register tcp://10.2.0.46:33945\\ndistributed.scheduler - INFO - Register tcp://10.2.0.5:33203\\ndistributed.scheduler - INFO - Register tcp://10.2.0.25:36359\\ndistributed.scheduler - INFO - Register tcp://10.2.0.38:42287\\ndistributed.scheduler - INFO - Register tcp://10.2.0.18:40539\\ndistributed.scheduler - INFO - Register tcp://10.2.0.36:36065\\ndistributed.scheduler - INFO - Register tcp://10.2.0.29:33085\\ndistributed.scheduler - INFO - Register tcp://10.2.0.19:35447\\ndistributed.scheduler - INFO - Register tcp://10.2.0.32:41815\\ndistributed.scheduler - INFO - Register tcp://10.2.0.35:44683\\ndistributed.scheduler - INFO - Register tcp://10.2.0.13:46307\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.12:45511\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.8:38963\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.43:42003\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.44:38063\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.27:38289\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.21:42337\\ndistributed.scheduler - INFO - Register tcp://10.2.0.6:37791\\ndistributed.worker - INFO -         Registered to:        tcp://10.2.0.5:8786\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.33:39413\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.39:40645\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.45:45855\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.23:34679\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.7:34619\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.46:33945\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.5:33203\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.25:36359\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.38:42287\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.18:40539\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.36:36065\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.29:33085\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.19:35447\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.32:41815\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.35:44683\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.13:46307\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.11:35365\\ndistributed.scheduler - INFO - Register tcp://10.2.0.34:44701\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.21:42337\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.6:37791\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.10:34465\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.10:34465\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.9:37653\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.9:37653\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.42:33651\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.42:33651\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.30:44499\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.30:44499\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.14:35141\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.14:35141\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.24:45185\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.24:45185\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.11:35365\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.34:44701\\ndistributed.core - INFO - Starting established connection\\ndistributed.protocol.pickle - INFO - Failed to deserialize b\\\"\\\\x80\\\\x04\\\\x951\\\\x11\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00(\\\\x8c\\\\x11dask.optimization\\\\x94\\\\x8c\\\\x10SubgraphCallable\\\\x94\\\\x93\\\\x94(}\\\\x94(\\\\x8c5drop_by_shallow_copy-1eb436d2f3f3dd0da551a68fdf080bb9\\\\x94(\\\\x8c\\\\ndask.utils\\\\x94\\\\x8c\\\\x05apply\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x13dask.dataframe.core\\\\x94\\\\x8c\\\\x11apply_and_enforce\\\\x94\\\\x93\\\\x94]\\\\x94(\\\\x8c'assign-9f1ed1acabd87b3d85213034009616f4\\\\x94\\\\x8c\\\\x02_0\\\\x94e\\\\x8c\\\\x08builtins\\\\x94\\\\x8c\\\\x04dict\\\\x94\\\\x93\\\\x94]\\\\x94(]\\\\x94(\\\\x8c\\\\x05_func\\\\x94\\\\x8c\\\\x14dask.dataframe.utils\\\\x94\\\\x8c\\\\x14drop_by_shallow_copy\\\\x94\\\\x93\\\\x94e]\\\\x94(\\\\x8c\\\\x05_meta\\\\x94\\\\x8c\\\\x11pandas.core.frame\\\\x94\\\\x8c\\\\tDataFrame\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94(\\\\x8c\\\\x05_data\\\\x94\\\\x8c\\\\x15pandas.core.internals\\\\x94\\\\x8c\\\\x0cBlockManager\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94(]\\\\x94(\\\\x8c\\\\x18pandas.core.indexes.base\\\\x94\\\\x8c\\\\n_new_Index\\\\x94\\\\x93\\\\x94h$\\\\x8c\\\\x05Index\\\\x94\\\\x93\\\\x94}\\\\x94(\\\\x8c\\\\x04data\\\\x94\\\\x8c\\\\x15numpy.core.multiarray\\\\x94\\\\x8c\\\\x0c_reconstruct\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x05numpy\\\\x94\\\\x8c\\\\x07ndarray\\\\x94\\\\x93\\\\x94K\\\\x00\\\\x85\\\\x94C\\\\x01b\\\\x94\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x14\\\\x85\\\\x94h.\\\\x8c\\\\x05dtype\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x02O8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03\\\\x8c\\\\x01|\\\\x94NNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK?t\\\\x94b\\\\x89]\\\\x94(\\\\x8c\\\\x04usaf\\\\x94\\\\x8c\\\\x04wban\\\\x94\\\\x8c\\\\x08latitude\\\\x94\\\\x8c\\\\tlongitude\\\\x94\\\\x8c\\\\televation\\\\x94\\\\x8c\\\\twindAngle\\\\x94\\\\x8c\\\\twindSpeed\\\\x94\\\\x8c\\\\x0eseaLvlPressure\\\\x94\\\\x8c\\\\rcloudCoverage\\\\x94\\\\x8c\\\\x17presentWeatherIndicator\\\\x94\\\\x8c\\\\x14pastWeatherIndicator\\\\x94\\\\x8c\\\\nprecipTime\\\\x94\\\\x8c\\\\x0bprecipDepth\\\\x94\\\\x8c\\\\tsnowDepth\\\\x94\\\\x8c\\\\x0bstationName\\\\x94\\\\x8c\\\\x0fcountryOrRegion\\\\x94\\\\x8c\\\\x03p_k\\\\x94\\\\x8c\\\\x04year\\\\x94\\\\x8c\\\\x03day\\\\x94\\\\x8c\\\\x05month\\\\x94et\\\\x94b\\\\x8c\\\\x04name\\\\x94Nu\\\\x86\\\\x94R\\\\x94h&\\\\x8c\\\\x19pandas.core.indexes.range\\\\x94\\\\x8c\\\\nRangeIndex\\\\x94\\\\x93\\\\x94}\\\\x94(hSN\\\\x8c\\\\x05start\\\\x94K\\\\x00\\\\x8c\\\\x04stop\\\\x94K\\\\x00\\\\x8c\\\\x04step\\\\x94K\\\\x01u\\\\x86\\\\x94R\\\\x94e]\\\\x94(h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06K\\\\x00\\\\x86\\\\x94h:\\\\x89]\\\\x94t\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x08K\\\\x00\\\\x86\\\\x94h7\\\\x8c\\\\x02f8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03\\\\x8c\\\\x01<\\\\x94NNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK\\\\x00t\\\\x94b\\\\x89C\\\\x00\\\\x94t\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05K\\\\x00\\\\x86\\\\x94h7\\\\x8c\\\\x02i4\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03hmNNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK\\\\x00t\\\\x94b\\\\x89hot\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x01K\\\\x00\\\\x86\\\\x94h7\\\\x8c\\\\x02i8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03hmNNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK\\\\x00t\\\\x94b\\\\x89hot\\\\x94be]\\\\x94(h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06\\\\x85\\\\x94h:\\\\x89]\\\\x94(h>h?hFhLhMhNet\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x08\\\\x85\\\\x94h:\\\\x89]\\\\x94(h@hAhBhDhEhIhJhKet\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05\\\\x85\\\\x94h:\\\\x89]\\\\x94(hChGhHhOhPet\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x01\\\\x85\\\\x94h:\\\\x89]\\\\x94hQat\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94e}\\\\x94\\\\x8c\\\\x060.14.1\\\\x94}\\\\x94(\\\\x8c\\\\x04axes\\\\x94h#\\\\x8c\\\\x06blocks\\\\x94]\\\\x94(}\\\\x94(\\\\x8c\\\\x06values\\\\x94hb\\\\x8c\\\\x08mgr_locs\\\\x94h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06\\\\x85\\\\x94h\\\\x80\\\\x89C0\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x01\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x08\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0e\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0f\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x10\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bu}\\\\x94(h\\\\xafhhh\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x08\\\\x85\\\\x94h\\\\x80\\\\x89C@\\\\x02\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x03\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x04\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x06\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x07\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0b\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0c\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\r\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bu}\\\\x94(h\\\\xafhsh\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05\\\\x85\\\\x94h\\\\x80\\\\x89C(\\\\x05\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\t\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\n\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x11\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x12\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bu}\\\\x94(h\\\\xafh|h\\\\xb0h\\\\x0e\\\\x8c\\\\x05slice\\\\x94\\\\x93\\\\x94K\\\\x13K\\\\x14K\\\\x01\\\\x87\\\\x94R\\\\x94ueust\\\\x94b\\\\x8c\\\\x04_typ\\\\x94\\\\x8c\\\\tdataframe\\\\x94\\\\x8c\\\\t_metadata\\\\x94]\\\\x94ube]\\\\x94(\\\\x8c\\\\x06errors\\\\x94\\\\x8c\\\\x05raise\\\\x94ee\\\\x86\\\\x94t\\\\x94h\\\\x0c(\\\\x8c\\\\x16dask.dataframe.methods\\\\x94\\\\x8c\\\\x06assign\\\\x94\\\\x93\\\\x94\\\\x8c'fillna-ad2330fa66156eef706e40f6ea22a8f6\\\\x94\\\\x8c\\\\x02_2\\\\x94\\\\x8c)dt-month-fd72f74d58f2de24ac49ed67e72c552a\\\\x94t\\\\x94h\\\\xd9(h\\\\x07h\\\\n]\\\\x94(\\\\x8c(getitem-f5ed0cddf246d10aa558103ce515cd9a\\\\x94\\\\x8c\\\\x02_3\\\\x94h\\\\xd8eh\\\\x10]\\\\x94(]\\\\x94(h\\\\x13\\\\x8c\\\\x17dask.dataframe.accessor\\\\x94\\\\x8c\\\\x1bAccessor._delegate_property\\\\x94\\\\x93\\\\x94e]\\\\x94(h\\\\x18\\\\x8c\\\\x12pandas.core.series\\\\x94\\\\x8c\\\\x06Series\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94(h\\\\x1eh\\\\x1f\\\\x8c\\\\x12SingleBlockManager\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94(]\\\\x94h&hX}\\\\x94(hSNhZK\\\\x00h[K\\\\x00h\\\\\\\\K\\\\x01u\\\\x86\\\\x94R\\\\x94a]\\\\x94h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x00\\\\x85\\\\x94h\\\\x80\\\\x89hot\\\\x94ba]\\\\x94h&\\\\x8c\\\\x1bpandas.core.indexes.numeric\\\\x94\\\\x8c\\\\nInt64Index\\\\x94\\\\x93\\\\x94}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x00\\\\x85\\\\x94h\\\\x80\\\\x89hot\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94a}\\\\x94h\\\\xa9}\\\\x94(h\\\\xabh\\\\xech\\\\xac]\\\\x94}\\\\x94(h\\\\xafh\\\\xf3h\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x00\\\\x85\\\\x94h\\\\x80\\\\x89hot\\\\x94buaust\\\\x94bh\\\\xcb\\\\x8c\\\\x06series\\\\x94h\\\\xcd]\\\\x94hSahS\\\\x8c\\\\x08datetime\\\\x94ubee\\\\x86\\\\x94t\\\\x94h\\\\xdc\\\\x8c\\\\t_operator\\\\x94\\\\x8c\\\\x07getitem\\\\x94\\\\x93\\\\x94h\\\\xd7\\\\x8c\\\\x02_5\\\\x94\\\\x87\\\\x94h\\\\xd7(h\\\\x07h\\\\x05\\\\x8c\\\\x0cmethodcaller\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x06fillna\\\\x94\\\\x85\\\\x94R\\\\x94]\\\\x94(\\\\x8c\\\\x02_6\\\\x94\\\\x8c\\\\x02_7\\\\x94eh\\\\x10]\\\\x94(]\\\\x94(\\\\x8c\\\\x06method\\\\x94Ne]\\\\x94(\\\\x8c\\\\x05limit\\\\x94Ne]\\\\x94(\\\\x8c\\\\x04axis\\\\x94K\\\\x00ee\\\\x86\\\\x94t\\\\x94uh\\\\x04(\\\\x8c\\\\x02_0\\\\x94\\\\x8c\\\\x02_1\\\\x94\\\\x8c\\\\x02_2\\\\x94\\\\x8c\\\\x02_3\\\\x94\\\\x8c\\\\x02_4\\\\x94\\\\x8c\\\\x02_5\\\\x94\\\\x8c\\\\x02_6\\\\x94\\\\x8c\\\\x02_7\\\\x94\\\\x8c\\\\x02_8\\\\x94t\\\\x94\\\\x8c\\\\x11subgraph_callable\\\\x94t\\\\x94R\\\\x94]\\\\x94(\\\\x8c\\\\x0btemperature\\\\x94\\\\x8c\\\\x08datetime\\\\x94\\\\x8c\\\\x07version\\\\x94eh\\\\x0chQ\\\\x8c\\\\x02dt\\\\x94h\\\\xdcj6\\\\x01\\\\x00\\\\x00(\\\\x8c\\\\x1edask.dataframe.io.parquet.core\\\\x94\\\\x8c\\\\x11read_parquet_part\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x1fdask.dataframe.io.parquet.arrow\\\\x94\\\\x8c\\\\x1aArrowEngine.read_partition\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x0bfsspec.spec\\\\x94\\\\x8c\\\\rmake_instance\\\\x94\\\\x93\\\\x94\\\\x8c\\\\nadlfs.core\\\\x94\\\\x8c\\\\x13AzureBlobFileSystem\\\\x94\\\\x93\\\\x94)}\\\\x94(\\\\x8c\\\\x0econtainer_name\\\\x94\\\\x8c\\\\x08datasets\\\\x94\\\\x8c\\\\x0caccount_name\\\\x94\\\\x8c\\\\tdata4dask\\\\x94\\\\x8c\\\\x0baccount_key\\\\x94\\\\x8cXmupxHTCWrYQC252cFAWCAm7lSlMPTCt5J3j7FCXIlXW/k3OIdLrWssVnMGKVX6N96XoIlw9O8PkQya3cNB9xKw==\\\\x94u\\\\x87\\\\x94R\\\\x94h\\\\x1b)\\\\x81\\\\x94}\\\\x94(h\\\\x1eh!)\\\\x81\\\\x94(]\\\\x94(h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x16\\\\x85\\\\x94h7\\\\x8c\\\\x02O8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03h;NNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK?t\\\\x94b\\\\x89]\\\\x94(h>h?j\\\\x0e\\\\x01\\\\x00\\\\x00h@hAhBhChD\\\\x8c\\\\x0btemperature\\\\x94hEhFhGhHhIhJhKhLhMhNhOhP\\\\x8c\\\\x07version\\\\x94et\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&hX}\\\\x94(hSNhZK\\\\x00h[K\\\\x00h\\\\\\\\K\\\\x01u\\\\x86\\\\x94R\\\\x94e]\\\\x94(h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06K\\\\x00\\\\x86\\\\x94jY\\\\x01\\\\x00\\\\x00\\\\x89]\\\\x94t\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x01K\\\\x00\\\\x86\\\\x94h7\\\\x8c\\\\x02M8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x04hmNNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK\\\\x00}\\\\x94(C\\\\x02ns\\\\x94K\\\\x01K\\\\x01K\\\\x01t\\\\x94\\\\x86\\\\x94t\\\\x94b\\\\x89hot\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\nK\\\\x00\\\\x86\\\\x94hl\\\\x89hot\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05K\\\\x00\\\\x86\\\\x94hw\\\\x89hot\\\\x94be]\\\\x94(h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06\\\\x85\\\\x94jY\\\\x01\\\\x00\\\\x00\\\\x89]\\\\x94(h>h?hFhLhMhNet\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x01\\\\x85\\\\x94jY\\\\x01\\\\x00\\\\x00\\\\x89]\\\\x94j\\\\x0e\\\\x01\\\\x00\\\\x00at\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\n\\\\x85\\\\x94jY\\\\x01\\\\x00\\\\x00\\\\x89]\\\\x94(h@hAhBhDj\\\\\\\\\\\\x01\\\\x00\\\\x00hEhIhJhKj]\\\\x01\\\\x00\\\\x00et\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05\\\\x85\\\\x94jY\\\\x01\\\\x00\\\\x00\\\\x89]\\\\x94(hChGhHhOhPet\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94e}\\\\x94h\\\\xa9}\\\\x94(h\\\\xabjQ\\\\x01\\\\x00\\\\x00h\\\\xac]\\\\x94(}\\\\x94(h\\\\xafjg\\\\x01\\\\x00\\\\x00h\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06\\\\x85\\\\x94h7\\\\x8c\\\\x02i8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03hmNNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK\\\\x00t\\\\x94b\\\\x89C0\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x01\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\n\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x10\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x11\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x12\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bu}\\\\x94(h\\\\xafjm\\\\x01\\\\x00\\\\x00h\\\\xb0h\\\\xc7K\\\\x02K\\\\x03K\\\\x01\\\\x87\\\\x94R\\\\x94u}\\\\x94(h\\\\xafjz\\\\x01\\\\x00\\\\x00h\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\n\\\\x85\\\\x94j\\\\xb1\\\\x01\\\\x00\\\\x00\\\\x89CP\\\\x03\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x04\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x05\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x07\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x08\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\t\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\r\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0e\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0f\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x15\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bu}\\\\x94(h\\\\xafj\\\\x7f\\\\x01\\\\x00\\\\x00h\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05\\\\x85\\\\x94j\\\\xb1\\\\x01\\\\x00\\\\x00\\\\x89C(\\\\x06\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0b\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0c\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x13\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x14\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bueust\\\\x94bh\\\\xcb\\\\x8c\\\\tdataframe\\\\x94h\\\\xcd]\\\\x94ub\\\\x8cynoaa/isd/year=2014/month=2/part-00011-tid-9219175779481662582-3729dfdb-ab32-4767-b9b6-11d2d644c3ce-90.c000.snappy.parquet\\\\x94N]\\\\x94\\\\x87\\\\x94]\\\\x94(h>h?j\\\\x0e\\\\x01\\\\x00\\\\x00h@hAhBhChDj\\\\\\\\\\\\x01\\\\x00\\\\x00hEhFhGhHhIhJhKhLhMhNhOhPj]\\\\x01\\\\x00\\\\x00eN}\\\\x94(\\\\x8c\\\\npartitions\\\\x94N\\\\x8c\\\\ncategories\\\\x94Nut\\\\x94K\\\\x00\\\\x8c-read-parquet-988028e491775459c2507adcc3fad764\\\\x94t\\\\x94.\\\"\\nTraceback (most recent call last):\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/pickle.py\\\", line 59, in loads\\n    return pickle.loads(x)\\nAttributeError: Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.protocol.core - CRITICAL - Failed to deserialize\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\nTraceback (most recent call last):\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/core.py\\\", line 124, in loads\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\n    value = _deserialize(head, fs, deserializers=deserializers)\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 268, in deserialize\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\n    return loads(header, frames)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 62, in pickle_loads\\n    return pickle.loads(b\\\"\\\".join(frames))\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/pickle.py\\\", line 59, in loads\\n    return pickle.loads(x)\\nAttributeError: Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.core - ERROR - Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\nTraceback (most recent call last):\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.18:40539\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/core.py\\\", line 447, in handle_stream\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.18:40539\\n    msgs = await comm.read()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/tcp.py\\\", line 208, in read\\n    frames, deserialize=self.deserialize, deserializers=deserializers\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.21:42337\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/tornado/gen.py\\\", line 209, in wrapper\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.21:42337\\n    yielded = next(result)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 66, in from_frames\\n    res = _from_frames()\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.23:34679\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 52, in _from_frames\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.23:34679\\n    frames, deserialize=deserialize, deserializers=deserializers\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/core.py\\\", line 124, in loads\\n    value = _deserialize(head, fs, deserializers=deserializers)\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.6:37791\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 268, in deserialize\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.6:37791\\n    return loads(header, frames)\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.29:33085\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 62, in pickle_loads\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.29:33085\\n    return pickle.loads(b\\\"\\\".join(frames))\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/pickle.py\\\", line 59, in loads\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.32:41815\\n    return pickle.loads(x)\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.32:41815\\nAttributeError: Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.worker - ERROR - Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\nTraceback (most recent call last):\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/worker.py\\\", line 904, in handle_scheduler\\n    comm, every_cycle=[self.ensure_communicating, self.ensure_computing]\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/core.py\\\", line 447, in handle_stream\\n    msgs = await comm.read()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/tcp.py\\\", line 208, in read\\n    frames, deserialize=self.deserialize, deserializers=deserializers\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/tornado/gen.py\\\", line 209, in wrapper\\n    yielded = next(result)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 66, in from_frames\\n    res = _from_frames()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 52, in _from_frames\\n    frames, deserialize=deserialize, deserializers=deserializers\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.38:42287\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/core.py\\\", line 124, in loads\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.38:42287\\n    value = _deserialize(head, fs, deserializers=deserializers)\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.44:38063\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 268, in deserialize\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.44:38063\\n    return loads(header, frames)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 62, in pickle_loads\\n    return pickle.loads(b\\\"\\\".join(frames))\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.45:45855\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/pickle.py\\\", line 59, in loads\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.45:45855\\n    return pickle.loads(x)\\nAttributeError: Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.5:33203\\ndistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.5:33203\\ntornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f3778a3b588>>, <Task finished coro=<Worker.handle_scheduler() done, defined at /azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/worker.py:901> exception=AttributeError(\\\"Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\\",)>)\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.46:33945\\nTraceback (most recent call last):\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.46:33945\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/tornado/ioloop.py\\\", line 743, in _run_callback\\n    ret = callback()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/tornado/ioloop.py\\\", line 767, in _discard_future_result\\n    future.result()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/worker.py\\\", line 904, in handle_scheduler\\n    comm, every_cycle=[self.ensure_communicating, self.ensure_computing]\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/core.py\\\", line 447, in handle_stream\\n    msgs = await comm.read()\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.36:36065\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/tcp.py\\\", line 208, in read\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.36:36065\\n    frames, deserialize=self.deserialize, deserializers=deserializers\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/tornado/gen.py\\\", line 209, in wrapper\\n    yielded = next(result)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 66, in from_frames\\n    res = _from_frames()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 52, in _from_frames\\n    frames, deserialize=deserialize, deserializers=deserializers\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/core.py\\\", line 124, in loads\\n    value = _deserialize(head, fs, deserializers=deserializers)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 268, in deserialize\\n    return loads(header, frames)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 62, in pickle_loads\\n    return pickle.loads(b\\\"\\\".join(frames))\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/pickle.py\\\", line 59, in loads\\n    return pickle.loads(x)\\nAttributeError: Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.scheduler - INFO - Register tcp://10.2.0.10:34465\\ndistributed.scheduler - INFO - Register tcp://10.2.0.14:35141\\ndistributed.scheduler - INFO - Register tcp://10.2.0.30:44499\\ndistributed.scheduler - INFO - Register tcp://10.2.0.9:37653\\ndistributed.scheduler - INFO - Register tcp://10.2.0.42:33651\\ndistributed.scheduler - INFO - Register tcp://10.2.0.24:45185\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.11:35365\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.11:35365\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.10:34465\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.14:35141\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.30:44499\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.9:37653\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.42:33651\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.24:45185\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.5:33203\\ndistributed.scheduler - INFO - Register tcp://10.2.0.18:40539\\ndistributed.scheduler - INFO - Register tcp://10.2.0.21:42337\\ndistributed.scheduler - INFO - Register tcp://10.2.0.32:41815\\ndistributed.scheduler - INFO - Register tcp://10.2.0.23:34679\\ndistributed.scheduler - INFO - Register tcp://10.2.0.38:42287\\ndistributed.scheduler - INFO - Register tcp://10.2.0.29:33085\\ndistributed.scheduler - INFO - Register tcp://10.2.0.44:38063\\ndistributed.scheduler - INFO - Register tcp://10.2.0.45:45855\\ndistributed.scheduler - INFO - Register tcp://10.2.0.46:33945\\ndistributed.scheduler - INFO - Register tcp://10.2.0.6:37791\\ndistributed.scheduler - INFO - Register tcp://10.2.0.36:36065\\ndistributed.scheduler - INFO - Register tcp://10.2.0.11:35365\\ndistributed.worker - INFO -         Registered to:        tcp://10.2.0.5:8786\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.5:33203\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.18:40539\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.21:42337\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.32:41815\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.23:34679\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.38:42287\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.29:33085\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.44:38063\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.45:45855\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.46:33945\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.6:37791\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.10:34465\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.10:34465\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.30:44499\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.30:44499\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.36:36065\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.11:35365\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.10:34465\\ndistributed.scheduler - INFO - Register tcp://10.2.0.30:44499\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.10:34465\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.30:44499\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.26:38687\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.26:38687\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.41:41673\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.41:41673\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.10:34465\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.10:34465\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.21:42337\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.21:42337\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.29:33085\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.29:33085\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.30:44499\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.30:44499\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.32:41815\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.32:41815\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.44:38063\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.44:38063\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.38:42287\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.38:42287\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.23:34679\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.23:34679\\ndistributed.scheduler - INFO - Register tcp://10.2.0.26:38687\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.17:37545\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.17:37545\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.43:42003\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.43:42003\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.26:38687\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.21:42337\\ndistributed.scheduler - INFO - Register tcp://10.2.0.29:33085\\ndistributed.scheduler - INFO - Register tcp://10.2.0.32:41815\\ndistributed.scheduler - INFO - Register tcp://10.2.0.23:34679\\ndistributed.scheduler - INFO - Register tcp://10.2.0.30:44499\\ndistributed.scheduler - INFO - Register tcp://10.2.0.44:38063\\ndistributed.scheduler - INFO - Register tcp://10.2.0.41:41673\\ndistributed.scheduler - INFO - Register tcp://10.2.0.38:42287\\ndistributed.scheduler - INFO - Register tcp://10.2.0.10:34465\\ndistributed.scheduler - INFO - Register tcp://10.2.0.17:37545\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.35:44683\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.35:44683\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.37:33723\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.37:33723\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.12:45511\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.12:45511\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.21:42337\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.29:33085\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.32:41815\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.23:34679\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.30:44499\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.44:38063\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.41:41673\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.8:38963\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.8:38963\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.38:42287\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.10:34465\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.17:37545\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.39:40645\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.39:40645\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.27:38289\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.27:38289\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.scheduler - INFO - Register tcp://10.2.0.43:42003\\ndistributed.scheduler - INFO - Register tcp://10.2.0.37:33723\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.7:34619\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.7:34619\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.33:39413\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.33:39413\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.19:35447\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.19:35447\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.13:46307\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.13:46307\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.26:38687\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.26:38687\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.10:34465\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.10:34465\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.43:42003\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.37:33723\\ndistributed.core - INFO - Starting established connection\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.scheduler - INFO - Register tcp://10.2.0.35:44683\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.25:36359\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.25:36359\\ndistributed.scheduler - INFO - Register tcp://10.2.0.8:38963\\ndistributed.scheduler - INFO - Register tcp://10.2.0.12:45511\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.34:44701\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.34:44701\\ndistributed.batched - INFO - Batched Comm Closed: in <closed TCP>: Stream is closed\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.41:41673\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.41:41673\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.35:44683\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.14:35141\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.14:35141\\ndistributed.scheduler - INFO - Register tcp://10.2.0.39:40645\\ndistributed.scheduler - INFO - Register tcp://10.2.0.26:38687\\ndistributed.scheduler - INFO - Register tcp://10.2.0.7:34619\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.8:38963\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.12:45511\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.10:34465\\ndistributed.scheduler - INFO - Register tcp://10.2.0.27:38289\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.17:37545\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.17:37545\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.43:42003\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.43:42003\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.24:45185\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.24:45185\\ndistributed.scheduler - INFO - Register tcp://10.2.0.19:35447\\ndistributed.scheduler - INFO - Register tcp://10.2.0.33:39413\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.39:40645\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.26:38687\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.7:34619\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.10:34465\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.27:38289\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.41:41673\\ndistributed.scheduler - INFO - Register tcp://10.2.0.13:46307\\ndistributed.scheduler - INFO - Register tcp://10.2.0.34:44701\\ndistributed.scheduler - INFO - Register tcp://10.2.0.25:36359\\ndistributed.scheduler - INFO - Register tcp://10.2.0.17:37545\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.19:35447\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.33:39413\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.43:42003\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.41:41673\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.13:46307\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.34:44701\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.25:36359\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.17:37545\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.14:35141\\ndistributed.scheduler - INFO - Register tcp://10.2.0.24:45185\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.43:42003\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.14:35141\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.24:45185\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.42:33651\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.42:33651\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.9:37653\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.9:37653\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.18:40539\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.18:40539\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.46:33945\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.46:33945\\ndistributed.scheduler - INFO - Register tcp://10.2.0.42:33651\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.42:33651\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.9:37653\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.9:37653\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.18:40539\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.18:40539\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.46:33945\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.46:33945\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.36:36065\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.36:36065\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.11:35365\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.11:35365\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.7:34619\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.7:34619\\ndistributed.protocol.pickle - INFO - Failed to deserialize b\\\"\\\\x80\\\\x04\\\\x955\\\\x11\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00(\\\\x8c\\\\x11dask.optimization\\\\x94\\\\x8c\\\\x10SubgraphCallable\\\\x94\\\\x93\\\\x94(}\\\\x94(\\\\x8c5drop_by_shallow_copy-1eb436d2f3f3dd0da551a68fdf080bb9\\\\x94(\\\\x8c\\\\ndask.utils\\\\x94\\\\x8c\\\\x05apply\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x13dask.dataframe.core\\\\x94\\\\x8c\\\\x11apply_and_enforce\\\\x94\\\\x93\\\\x94]\\\\x94(\\\\x8c'assign-9f1ed1acabd87b3d85213034009616f4\\\\x94\\\\x8c\\\\x02_0\\\\x94e\\\\x8c\\\\x08builtins\\\\x94\\\\x8c\\\\x04dict\\\\x94\\\\x93\\\\x94]\\\\x94(]\\\\x94(\\\\x8c\\\\x05_func\\\\x94\\\\x8c\\\\x14dask.dataframe.utils\\\\x94\\\\x8c\\\\x14drop_by_shallow_copy\\\\x94\\\\x93\\\\x94e]\\\\x94(\\\\x8c\\\\x05_meta\\\\x94\\\\x8c\\\\x11pandas.core.frame\\\\x94\\\\x8c\\\\tDataFrame\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94(\\\\x8c\\\\x05_data\\\\x94\\\\x8c\\\\x15pandas.core.internals\\\\x94\\\\x8c\\\\x0cBlockManager\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94(]\\\\x94(\\\\x8c\\\\x18pandas.core.indexes.base\\\\x94\\\\x8c\\\\n_new_Index\\\\x94\\\\x93\\\\x94h$\\\\x8c\\\\x05Index\\\\x94\\\\x93\\\\x94}\\\\x94(\\\\x8c\\\\x04data\\\\x94\\\\x8c\\\\x15numpy.core.multiarray\\\\x94\\\\x8c\\\\x0c_reconstruct\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x05numpy\\\\x94\\\\x8c\\\\x07ndarray\\\\x94\\\\x93\\\\x94K\\\\x00\\\\x85\\\\x94C\\\\x01b\\\\x94\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x14\\\\x85\\\\x94h.\\\\x8c\\\\x05dtype\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x02O8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03\\\\x8c\\\\x01|\\\\x94NNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK?t\\\\x94b\\\\x89]\\\\x94(\\\\x8c\\\\x04usaf\\\\x94\\\\x8c\\\\x04wban\\\\x94\\\\x8c\\\\x08latitude\\\\x94\\\\x8c\\\\tlongitude\\\\x94\\\\x8c\\\\televation\\\\x94\\\\x8c\\\\twindAngle\\\\x94\\\\x8c\\\\twindSpeed\\\\x94\\\\x8c\\\\x0eseaLvlPressure\\\\x94\\\\x8c\\\\rcloudCoverage\\\\x94\\\\x8c\\\\x17presentWeatherIndicator\\\\x94\\\\x8c\\\\x14pastWeatherIndicator\\\\x94\\\\x8c\\\\nprecipTime\\\\x94\\\\x8c\\\\x0bprecipDepth\\\\x94\\\\x8c\\\\tsnowDepth\\\\x94\\\\x8c\\\\x0bstationName\\\\x94\\\\x8c\\\\x0fcountryOrRegion\\\\x94\\\\x8c\\\\x03p_k\\\\x94\\\\x8c\\\\x04year\\\\x94\\\\x8c\\\\x03day\\\\x94\\\\x8c\\\\x05month\\\\x94et\\\\x94b\\\\x8c\\\\x04name\\\\x94Nu\\\\x86\\\\x94R\\\\x94h&\\\\x8c\\\\x19pandas.core.indexes.range\\\\x94\\\\x8c\\\\nRangeIndex\\\\x94\\\\x93\\\\x94}\\\\x94(hSN\\\\x8c\\\\x05start\\\\x94K\\\\x00\\\\x8c\\\\x04stop\\\\x94K\\\\x00\\\\x8c\\\\x04step\\\\x94K\\\\x01u\\\\x86\\\\x94R\\\\x94e]\\\\x94(h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06K\\\\x00\\\\x86\\\\x94h:\\\\x89]\\\\x94t\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x08K\\\\x00\\\\x86\\\\x94h7\\\\x8c\\\\x02f8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03\\\\x8c\\\\x01<\\\\x94NNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK\\\\x00t\\\\x94b\\\\x89C\\\\x00\\\\x94t\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05K\\\\x00\\\\x86\\\\x94h7\\\\x8c\\\\x02i4\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03hmNNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK\\\\x00t\\\\x94b\\\\x89hot\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x01K\\\\x00\\\\x86\\\\x94h7\\\\x8c\\\\x02i8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03hmNNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK\\\\x00t\\\\x94b\\\\x89hot\\\\x94be]\\\\x94(h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06\\\\x85\\\\x94h:\\\\x89]\\\\x94(h>h?hFhLhMhNet\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x08\\\\x85\\\\x94h:\\\\x89]\\\\x94(h@hAhBhDhEhIhJhKet\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05\\\\x85\\\\x94h:\\\\x89]\\\\x94(hChGhHhOhPet\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x01\\\\x85\\\\x94h:\\\\x89]\\\\x94hQat\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94e}\\\\x94\\\\x8c\\\\x060.14.1\\\\x94}\\\\x94(\\\\x8c\\\\x04axes\\\\x94h#\\\\x8c\\\\x06blocks\\\\x94]\\\\x94(}\\\\x94(\\\\x8c\\\\x06values\\\\x94hb\\\\x8c\\\\x08mgr_locs\\\\x94h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06\\\\x85\\\\x94h\\\\x80\\\\x89C0\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x01\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x08\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0e\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0f\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x10\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bu}\\\\x94(h\\\\xafhhh\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x08\\\\x85\\\\x94h\\\\x80\\\\x89C@\\\\x02\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x03\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x04\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x06\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x07\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0b\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0c\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\r\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bu}\\\\x94(h\\\\xafhsh\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05\\\\x85\\\\x94h\\\\x80\\\\x89C(\\\\x05\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\t\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\n\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x11\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x12\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bu}\\\\x94(h\\\\xafh|h\\\\xb0h\\\\x0e\\\\x8c\\\\x05slice\\\\x94\\\\x93\\\\x94K\\\\x13K\\\\x14K\\\\x01\\\\x87\\\\x94R\\\\x94ueust\\\\x94b\\\\x8c\\\\x04_typ\\\\x94\\\\x8c\\\\tdataframe\\\\x94\\\\x8c\\\\t_metadata\\\\x94]\\\\x94ube]\\\\x94(\\\\x8c\\\\x06errors\\\\x94\\\\x8c\\\\x05raise\\\\x94ee\\\\x86\\\\x94t\\\\x94h\\\\x0c(\\\\x8c\\\\x16dask.dataframe.methods\\\\x94\\\\x8c\\\\x06assign\\\\x94\\\\x93\\\\x94\\\\x8c'fillna-ad2330fa66156eef706e40f6ea22a8f6\\\\x94\\\\x8c\\\\x02_2\\\\x94\\\\x8c)dt-month-fd72f74d58f2de24ac49ed67e72c552a\\\\x94t\\\\x94h\\\\xd9(h\\\\x07h\\\\n]\\\\x94(\\\\x8c(getitem-f5ed0cddf246d10aa558103ce515cd9a\\\\x94\\\\x8c\\\\x02_3\\\\x94h\\\\xd8eh\\\\x10]\\\\x94(]\\\\x94(h\\\\x13\\\\x8c\\\\x17dask.dataframe.accessor\\\\x94\\\\x8c\\\\x1bAccessor._delegate_property\\\\x94\\\\x93\\\\x94e]\\\\x94(h\\\\x18\\\\x8c\\\\x12pandas.core.series\\\\x94\\\\x8c\\\\x06Series\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94}\\\\x94(h\\\\x1eh\\\\x1f\\\\x8c\\\\x12SingleBlockManager\\\\x94\\\\x93\\\\x94)\\\\x81\\\\x94(]\\\\x94h&hX}\\\\x94(hSNhZK\\\\x00h[K\\\\x00h\\\\\\\\K\\\\x01u\\\\x86\\\\x94R\\\\x94a]\\\\x94h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x00\\\\x85\\\\x94h\\\\x80\\\\x89hot\\\\x94ba]\\\\x94h&\\\\x8c\\\\x1bpandas.core.indexes.numeric\\\\x94\\\\x8c\\\\nInt64Index\\\\x94\\\\x93\\\\x94}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x00\\\\x85\\\\x94h\\\\x80\\\\x89hot\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94a}\\\\x94h\\\\xa9}\\\\x94(h\\\\xabh\\\\xech\\\\xac]\\\\x94}\\\\x94(h\\\\xafh\\\\xf3h\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x00\\\\x85\\\\x94h\\\\x80\\\\x89hot\\\\x94buaust\\\\x94bh\\\\xcb\\\\x8c\\\\x06series\\\\x94h\\\\xcd]\\\\x94hSahS\\\\x8c\\\\x08datetime\\\\x94ubee\\\\x86\\\\x94t\\\\x94h\\\\xdc\\\\x8c\\\\t_operator\\\\x94\\\\x8c\\\\x07getitem\\\\x94\\\\x93\\\\x94h\\\\xd7\\\\x8c\\\\x02_5\\\\x94\\\\x87\\\\x94h\\\\xd7(h\\\\x07h\\\\x05\\\\x8c\\\\x0cmethodcaller\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x06fillna\\\\x94\\\\x85\\\\x94R\\\\x94]\\\\x94(\\\\x8c\\\\x02_6\\\\x94\\\\x8c\\\\x02_7\\\\x94eh\\\\x10]\\\\x94(]\\\\x94(\\\\x8c\\\\x06method\\\\x94Ne]\\\\x94(\\\\x8c\\\\x05limit\\\\x94Ne]\\\\x94(\\\\x8c\\\\x04axis\\\\x94K\\\\x00ee\\\\x86\\\\x94t\\\\x94uh\\\\x04(\\\\x8c\\\\x02_0\\\\x94\\\\x8c\\\\x02_1\\\\x94\\\\x8c\\\\x02_2\\\\x94\\\\x8c\\\\x02_3\\\\x94\\\\x8c\\\\x02_4\\\\x94\\\\x8c\\\\x02_5\\\\x94\\\\x8c\\\\x02_6\\\\x94\\\\x8c\\\\x02_7\\\\x94\\\\x8c\\\\x02_8\\\\x94t\\\\x94\\\\x8c\\\\x11subgraph_callable\\\\x94t\\\\x94R\\\\x94]\\\\x94(\\\\x8c\\\\x0btemperature\\\\x94\\\\x8c\\\\x08datetime\\\\x94\\\\x8c\\\\x07version\\\\x94eh\\\\x0chQ\\\\x8c\\\\x02dt\\\\x94h\\\\xdcj6\\\\x01\\\\x00\\\\x00(\\\\x8c\\\\x1edask.dataframe.io.parquet.core\\\\x94\\\\x8c\\\\x11read_parquet_part\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x1fdask.dataframe.io.parquet.arrow\\\\x94\\\\x8c\\\\x1aArrowEngine.read_partition\\\\x94\\\\x93\\\\x94\\\\x8c\\\\x0bfsspec.spec\\\\x94\\\\x8c\\\\rmake_instance\\\\x94\\\\x93\\\\x94\\\\x8c\\\\nadlfs.core\\\\x94\\\\x8c\\\\x13AzureBlobFileSystem\\\\x94\\\\x93\\\\x94)}\\\\x94(\\\\x8c\\\\x0econtainer_name\\\\x94\\\\x8c\\\\x08datasets\\\\x94\\\\x8c\\\\x0caccount_name\\\\x94\\\\x8c\\\\tdata4dask\\\\x94\\\\x8c\\\\x0baccount_key\\\\x94\\\\x8cXmupxHTCWrYQC252cFAWCAm7lSlMPTCt5J3j7FCXIlXW/k3OIdLrWssVnMGKVX6N96XoIlw9O8PkQya3cNB9xKw==\\\\x94u\\\\x87\\\\x94R\\\\x94h\\\\x1b)\\\\x81\\\\x94}\\\\x94(h\\\\x1eh!)\\\\x81\\\\x94(]\\\\x94(h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x16\\\\x85\\\\x94h7\\\\x8c\\\\x02O8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03h;NNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK?t\\\\x94b\\\\x89]\\\\x94(h>h?j\\\\x0e\\\\x01\\\\x00\\\\x00h@hAhBhChD\\\\x8c\\\\x0btemperature\\\\x94hEhFhGhHhIhJhKhLhMhNhOhP\\\\x8c\\\\x07version\\\\x94et\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&hX}\\\\x94(hSNhZK\\\\x00h[K\\\\x00h\\\\\\\\K\\\\x01u\\\\x86\\\\x94R\\\\x94e]\\\\x94(h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06K\\\\x00\\\\x86\\\\x94jY\\\\x01\\\\x00\\\\x00\\\\x89]\\\\x94t\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x01K\\\\x00\\\\x86\\\\x94h7\\\\x8c\\\\x02M8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x04hmNNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK\\\\x00}\\\\x94(C\\\\x02ns\\\\x94K\\\\x01K\\\\x01K\\\\x01t\\\\x94\\\\x86\\\\x94t\\\\x94b\\\\x89hot\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\nK\\\\x00\\\\x86\\\\x94hl\\\\x89hot\\\\x94bh-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05K\\\\x00\\\\x86\\\\x94hw\\\\x89hot\\\\x94be]\\\\x94(h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06\\\\x85\\\\x94jY\\\\x01\\\\x00\\\\x00\\\\x89]\\\\x94(h>h?hFhLhMhNet\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x01\\\\x85\\\\x94jY\\\\x01\\\\x00\\\\x00\\\\x89]\\\\x94j\\\\x0e\\\\x01\\\\x00\\\\x00at\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\n\\\\x85\\\\x94jY\\\\x01\\\\x00\\\\x00\\\\x89]\\\\x94(h@hAhBhDj\\\\\\\\\\\\x01\\\\x00\\\\x00hEhIhJhKj]\\\\x01\\\\x00\\\\x00et\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94h&h(}\\\\x94(h*h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05\\\\x85\\\\x94jY\\\\x01\\\\x00\\\\x00\\\\x89]\\\\x94(hChGhHhOhPet\\\\x94bhSNu\\\\x86\\\\x94R\\\\x94e}\\\\x94h\\\\xa9}\\\\x94(h\\\\xabjQ\\\\x01\\\\x00\\\\x00h\\\\xac]\\\\x94(}\\\\x94(h\\\\xafjg\\\\x01\\\\x00\\\\x00h\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x06\\\\x85\\\\x94h7\\\\x8c\\\\x02i8\\\\x94K\\\\x00K\\\\x01\\\\x87\\\\x94R\\\\x94(K\\\\x03hmNNNJ\\\\xff\\\\xff\\\\xff\\\\xffJ\\\\xff\\\\xff\\\\xff\\\\xffK\\\\x00t\\\\x94b\\\\x89C0\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x01\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\n\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x10\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x11\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x12\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bu}\\\\x94(h\\\\xafjm\\\\x01\\\\x00\\\\x00h\\\\xb0h\\\\xc7K\\\\x02K\\\\x03K\\\\x01\\\\x87\\\\x94R\\\\x94u}\\\\x94(h\\\\xafjz\\\\x01\\\\x00\\\\x00h\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\n\\\\x85\\\\x94j\\\\xb1\\\\x01\\\\x00\\\\x00\\\\x89CP\\\\x03\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x04\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x05\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x07\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x08\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\t\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\r\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0e\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0f\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x15\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bu}\\\\x94(h\\\\xafj\\\\x7f\\\\x01\\\\x00\\\\x00h\\\\xb0h-h0K\\\\x00\\\\x85\\\\x94h2\\\\x87\\\\x94R\\\\x94(K\\\\x01K\\\\x05\\\\x85\\\\x94j\\\\xb1\\\\x01\\\\x00\\\\x00\\\\x89C(\\\\x06\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0b\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x0c\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x13\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x14\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x00\\\\x94t\\\\x94bueust\\\\x94bh\\\\xcb\\\\x8c\\\\tdataframe\\\\x94h\\\\xcd]\\\\x94ub\\\\x8c}noaa/isd/year=2018/month=9/part-00089-tid-9138739344806125380-ef942066-1d58-49f9-8ecb-3329cbe6e57e-383784.c000.snappy.parquet\\\\x94N]\\\\x94\\\\x87\\\\x94]\\\\x94(h>h?j\\\\x0e\\\\x01\\\\x00\\\\x00h@hAhBhChDj\\\\\\\\\\\\x01\\\\x00\\\\x00hEhFhGhHhIhJhKhLhMhNhOhPj]\\\\x01\\\\x00\\\\x00eN}\\\\x94(\\\\x8c\\\\npartitions\\\\x94N\\\\x8c\\\\ncategories\\\\x94Nut\\\\x94K\\\\x00\\\\x8c-read-parquet-988028e491775459c2507adcc3fad764\\\\x94t\\\\x94.\\\"\\nTraceback (most recent call last):\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/pickle.py\\\", line 59, in loads\\n    return pickle.loads(x)\\nAttributeError: Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.protocol.core - CRITICAL - Failed to deserialize\\nTraceback (most recent call last):\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.5:33203\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/core.py\\\", line 124, in loads\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.5:33203\\n    value = _deserialize(head, fs, deserializers=deserializers)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 268, in deserialize\\n    return loads(header, frames)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 62, in pickle_loads\\n    return pickle.loads(b\\\"\\\".join(frames))\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/pickle.py\\\", line 59, in loads\\n    return pickle.loads(x)\\nAttributeError: Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.core - ERROR - Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\nTraceback (most recent call last):\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/core.py\\\", line 447, in handle_stream\\n    msgs = await comm.read()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/tcp.py\\\", line 208, in read\\n    frames, deserialize=self.deserialize, deserializers=deserializers\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/tornado/gen.py\\\", line 209, in wrapper\\n    yielded = next(result)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 66, in from_frames\\n    res = _from_frames()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 52, in _from_frames\\n    frames, deserialize=deserialize, deserializers=deserializers\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/core.py\\\", line 124, in loads\\ndistributed.scheduler - INFO - Register tcp://10.2.0.36:36065\\n    value = _deserialize(head, fs, deserializers=deserializers)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 268, in deserialize\\n    return loads(header, frames)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 62, in pickle_loads\\n    return pickle.loads(b\\\"\\\".join(frames))\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/pickle.py\\\", line 59, in loads\\n    return pickle.loads(x)\\nAttributeError: Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.worker - ERROR - Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.36:36065\\nTraceback (most recent call last):\\ndistributed.core - INFO - Starting established connection\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/worker.py\\\", line 904, in handle_scheduler\\n    comm, every_cycle=[self.ensure_communicating, self.ensure_computing]\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/core.py\\\", line 447, in handle_stream\\n    msgs = await comm.read()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/tcp.py\\\", line 208, in read\\n    frames, deserialize=self.deserialize, deserializers=deserializers\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/tornado/gen.py\\\", line 209, in wrapper\\n    yielded = next(result)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 66, in from_frames\\n    res = _from_frames()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 52, in _from_frames\\n    frames, deserialize=deserialize, deserializers=deserializers\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/core.py\\\", line 124, in loads\\n    value = _deserialize(head, fs, deserializers=deserializers)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 268, in deserialize\\n    return loads(header, frames)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 62, in pickle_loads\\n    return pickle.loads(b\\\"\\\".join(frames))\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/pickle.py\\\", line 59, in loads\\n    return pickle.loads(x)\\nAttributeError: Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\\ntornado.application - ERROR - Exception in callback functools.partial(<bound method IOLoop._discard_future_result of <tornado.platform.asyncio.AsyncIOLoop object at 0x7f3778a3b588>>, <Task finished coro=<Worker.handle_scheduler() done, defined at /azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/worker.py:901> exception=AttributeError(\\\"Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\\",)>)\\nTraceback (most recent call last):\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/tornado/ioloop.py\\\", line 743, in _run_callback\\n    ret = callback()\\ndistributed.scheduler - INFO - Register tcp://10.2.0.7:34619\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/tornado/ioloop.py\\\", line 767, in _discard_future_result\\n    future.result()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/worker.py\\\", line 904, in handle_scheduler\\n    comm, every_cycle=[self.ensure_communicating, self.ensure_computing]\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/core.py\\\", line 447, in handle_stream\\n    msgs = await comm.read()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/tcp.py\\\", line 208, in read\\n    frames, deserialize=self.deserialize, deserializers=deserializers\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.7:34619\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/tornado/gen.py\\\", line 209, in wrapper\\ndistributed.core - INFO - Starting established connection\\n    yielded = next(result)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 66, in from_frames\\n    res = _from_frames()\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/comm/utils.py\\\", line 52, in _from_frames\\ndistributed.scheduler - INFO - Register tcp://10.2.0.11:35365\\n    frames, deserialize=deserialize, deserializers=deserializers\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/core.py\\\", line 124, in loads\\n    value = _deserialize(head, fs, deserializers=deserializers)\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 268, in deserialize\\n    return loads(header, frames)\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.11:35365\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/serialize.py\\\", line 62, in pickle_loads\\ndistributed.core - INFO - Starting established connection\\n    return pickle.loads(b\\\"\\\".join(frames))\\n  File \\\"/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/distributed/protocol/pickle.py\\\", line 59, in loads\\n    return pickle.loads(x)\\nAttributeError: Can't get attribute 'drop_by_shallow_copy' on <module 'dask.dataframe.utils' from '/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/dask/dataframe/utils.py'>\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.scheduler - INFO - Register tcp://10.2.0.5:33203\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.5:33203\\ndistributed.core - INFO - Starting established connection\\ndistributed.worker - INFO -         Registered to:        tcp://10.2.0.5:8786\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.38:42287\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.38:42287\\ndistributed.scheduler - INFO - Register tcp://10.2.0.38:42287\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.38:42287\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.40:42961\\ndistributed.scheduler - INFO - Register tcp://10.2.0.22:40181\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.40:42961\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.22:40181\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.28:45083\\ndistributed.scheduler - INFO - Register tcp://10.2.0.31:42135\\ndistributed.scheduler - INFO - Register tcp://10.2.0.20:42005\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.28:45083\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.31:42135\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.20:42005\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Unexpected worker completed task, likely due to work stealing.  Expected: tcp://10.2.0.6:37791, Got: tcp://10.2.0.35:44683, Key: ('read-parquet-getitem-0ed957666c73a64dd5981ce9676313ec', 75)\\ndistributed.scheduler - INFO - Unexpected worker completed task, likely due to work stealing.  Expected: tcp://10.2.0.10:34465, Got: tcp://10.2.0.5:33203, Key: ('read-parquet-getitem-0ed957666c73a64dd5981ce9676313ec', 88)\\ndistributed.scheduler - INFO - Unexpected worker completed task, likely due to work stealing.  Expected: tcp://10.2.0.21:42337, Got: tcp://10.2.0.12:45511, Key: ('read-parquet-getitem-0ed957666c73a64dd5981ce9676313ec', 25)\\ndistributed.scheduler - INFO - Unexpected worker completed task, likely due to work stealing.  Expected: tcp://10.2.0.45:45855, Got: tcp://10.2.0.9:37653, Key: ('read-parquet-getitem-0ed957666c73a64dd5981ce9676313ec', 63)\\ndistributed.scheduler - INFO - Send lost future signal to clients\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.10:34465\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.10:34465\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.11:35365\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.11:35365\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.12:45511\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.12:45511\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.13:46307\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.13:46307\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.14:35141\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.14:35141\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.17:37545\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.17:37545\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.18:40539\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.18:40539\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.19:35447\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.19:35447\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.20:42005\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.20:42005\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.21:42337\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.21:42337\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.22:40181\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.22:40181\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.23:34679\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.23:34679\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.24:45185\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.24:45185\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.25:36359\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.25:36359\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.26:38687\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.26:38687\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.27:38289\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.27:38289\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.28:45083\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.28:45083\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.29:33085\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.29:33085\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.30:44499\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.30:44499\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.31:42135\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.31:42135\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.32:41815\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.32:41815\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.33:39413\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.33:39413\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.34:44701\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.34:44701\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.35:44683\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.35:44683\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.36:36065\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.36:36065\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.37:33723\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.37:33723\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.38:42287\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.38:42287\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.39:40645\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.39:40645\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.40:42961\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.40:42961\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.41:41673\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.41:41673\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.42:33651\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.42:33651\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.43:42003\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.43:42003\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.44:38063\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.44:38063\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.45:45855\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.45:45855\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.46:33945\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.46:33945\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.5:33203\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.5:33203\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.6:37791\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.6:37791\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.7:34619\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.7:34619\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.8:38963\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.8:38963\\ndistributed.scheduler - INFO - Remove worker tcp://10.2.0.9:37653\\ndistributed.core - INFO - Removing comms to tcp://10.2.0.9:37653\\ndistributed.scheduler - INFO - Lost all workers\\ndistributed.scheduler - INFO - Clear task state\\ndistributed.worker - INFO - Stopping worker at tcp://10.2.0.5:33203\\ndistributed.scheduler - INFO - Register tcp://10.2.0.12:33339\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.12:33339\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.17:45187\\ndistributed.scheduler - INFO - Register tcp://10.2.0.41:35367\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.17:45187\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.41:35367\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.14:44897\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.14:44897\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.9:38931\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.9:38931\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.35:38993\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.35:38993\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.27:39003\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.27:39003\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.18:46669\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.18:46669\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.42:44305\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.42:44305\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.24:45501\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.24:45501\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.26:34253\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.26:34253\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.22:38601\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.22:38601\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.34:37465\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.34:37465\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.37:42023\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.37:42023\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.36:37251\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.36:37251\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.40:33539\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.40:33539\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.31:34835\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.31:34835\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.44:37379\\ndistributed.scheduler - INFO - Register tcp://10.2.0.33:33153\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.44:37379\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.33:33153\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.19:36631\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.19:36631\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.43:33729\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.43:33729\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.23:43639\\ndistributed.scheduler - INFO - Register tcp://10.2.0.38:37417\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.23:43639\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.38:37417\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.25:39363\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.25:39363\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.30:42165\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.30:42165\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.21:44383\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.21:44383\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.8:38521\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.8:38521\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.7:38435\\ndistributed.scheduler - INFO - Register tcp://10.2.0.6:41979\\ndistributed.scheduler - INFO - Register tcp://10.2.0.13:45529\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.7:38435\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.6:41979\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.46:33579\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.13:45529\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.46:33579\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.20:34537\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.20:34537\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.45:37903\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.45:37903\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.32:37273\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.32:37273\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.39:33793\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.39:33793\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.10:38199\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.10:38199\\ndistributed.core - INFO - Starting established connection\\ndistributed.worker - INFO -       Start worker at:       tcp://10.2.0.5:45427\\ndistributed.worker - INFO -          Listening to:       tcp://10.2.0.5:45427\\ndistributed.worker - INFO -          dashboard at:             10.2.0.5:35439\\ndistributed.worker - INFO - Waiting to connect to:        tcp://10.2.0.5:8786\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.worker - INFO -               Threads:                         16\\ndistributed.worker - INFO -                Memory:                  118.27 GB\\ndistributed.worker - INFO -       Local Directory: /mnt/batch/tasks/shared/LS_root/jobs/ncus-azureml/azureml/dask-xgboost_1578872294_ecf303d5/mounts/workspaceblobstore/azureml/dask-xgboost_1578872294_ecf303d5/worker-za1r3ieq\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.scheduler - INFO - Register tcp://10.2.0.5:45427\\ndistributed.scheduler - INFO - Register tcp://10.2.0.29:37203\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.5:45427\\ndistributed.worker - INFO -         Registered to:        tcp://10.2.0.5:8786\\ndistributed.core - INFO - Starting established connection\\ndistributed.worker - INFO - -------------------------------------------------\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.29:37203\\ndistributed.core - INFO - Starting established connection\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Register tcp://10.2.0.28:44467\\ndistributed.scheduler - INFO - Register tcp://10.2.0.11:37605\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.28:44467\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Starting worker compute stream, tcp://10.2.0.11:37605\\ndistributed.core - INFO - Starting established connection\\ndistributed.scheduler - INFO - Clear task state\\ndistributed.core - INFO - Event loop was unresponsive in Worker for 35.11s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\\ndistributed.core - INFO - Event loop was unresponsive in Worker for 7.85s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\\ndistributed.core - INFO - Event loop was unresponsive in Worker for 3.92s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\\ndistributed.worker - INFO - Run out-of-band function 'start_tracker'\\n/azureml-envs/azureml_ea1094eada22ba525e7c250d4322b500/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\\n  if getattr(data, 'base', None) is not None and \\\\\\ndistributed.core - INFO - Event loop was unresponsive in Worker for 9.22s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\\n[00:04:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\\n[00:04:09] WARNING: /workspace/src/learner.cc:622: Tree method is automatically selected to be 'approx' for distributed training.\\n[00:04:09] Tree method is automatically selected to be 'approx' for distributed training.\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.0.83\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waiting for scheduler node's ip\n",
      "\n",
      "Setting up port forwarding...\n",
      "Cluster is ready to use.\n",
      "\n",
      "\n",
      "<Client: 'tcp://10.2.0.5:8786' processes=40 threads=640, memory=4.73 TB>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"https://macbookpro-4242.northcentralus.instances.azureml.net/status\">Dashboard link</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# port to forward the dask dashboard to on the compute instance\n",
    "# we do not use 8787 because it is already in use \n",
    "dashboard_port = 4242\n",
    "\n",
    "print(\"waiting for scheduler node's ip\")\n",
    "while run.get_status() != 'Canceled' and 'scheduler' not in run.get_metrics():\n",
    "    print('.', end =\"\")\n",
    "    time.sleep(5)\n",
    "\n",
    "if run.get_status() == 'Canceled':\n",
    "    print('\\nRun was canceled')\n",
    "else:\n",
    "    print(f'\\nSetting up port forwarding...')\n",
    "    os.system(f'killall socat') # kill all socat processes - cleans up previous port forward setups \n",
    "    os.system(f'setsid socat tcp-listen:{dashboard_port},reuseaddr,fork tcp:{run.get_metrics()[\"dashboard\"]} &')\n",
    "    print(f'Cluster is ready to use.')\n",
    "\n",
    "c = Client(f'tcp://{run.get_metrics()[\"scheduler\"]}')\n",
    "\n",
    "print(f'\\n\\n{c}')\n",
    "\n",
    "c.restart()\n",
    "\n",
    "# need to get the dashboard link \n",
    "dashboard_url = f'https://{socket.gethostname()}-{dashboard_port}.{ws.get_details()[\"location\"]}.instances.azureml.net/status'\n",
    "HTML(f'<a href=\"{dashboard_url}\">Dashboard link</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol  = 'abfs'      # use 'adl' for Azure Data Lake Gen 1\n",
    "container = 'datasets'  # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = fsspec.filesystem(protocol, **STORAGE_OPTIONS, container_name=container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for file in fs.glob('noaa/isd/*/*'):\n",
    "    #print(fs.ls(f'{month}/'))\n",
    "    files += fs.ls(f'{file}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abfs://datasets/noaa/isd/year=2018/month=5/part-00066-tid-9138739344806125380-ef942066-1d58-49f9-8ecb-3329cbe6e57e-383761.c000.snappy.parquet',\n",
       " 'abfs://datasets/noaa/isd/year=2018/month=6/part-00049-tid-9138739344806125380-ef942066-1d58-49f9-8ecb-3329cbe6e57e-383744.c000.snappy.parquet',\n",
       " 'abfs://datasets/noaa/isd/year=2018/month=7/part-00107-tid-9138739344806125380-ef942066-1d58-49f9-8ecb-3329cbe6e57e-383859.c000.snappy.parquet',\n",
       " 'abfs://datasets/noaa/isd/year=2018/month=8/part-00103-tid-9138739344806125380-ef942066-1d58-49f9-8ecb-3329cbe6e57e-383807.c000.snappy.parquet',\n",
       " 'abfs://datasets/noaa/isd/year=2018/month=9/part-00089-tid-9138739344806125380-ef942066-1d58-49f9-8ecb-3329cbe6e57e-383784.c000.snappy.parquet']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f'{protocol}://{container}/{file}' for file in files if '2019' not in file]\n",
    "files[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dask.delayed(dd.read_parquet)(files, engine='pyarrow', storage_options=STORAGE_OPTIONS).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0) # optional but highly recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month'] = df['datetime'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['latitude',\n",
       " 'longitude',\n",
       " 'elevation',\n",
       " 'windAngle',\n",
       " 'windSpeed',\n",
       " 'temperature',\n",
       " 'seaLvlPressure',\n",
       " 'presentWeatherIndicator',\n",
       " 'pastWeatherIndicator',\n",
       " 'precipTime',\n",
       " 'precipDepth',\n",
       " 'snowDepth',\n",
       " 'year',\n",
       " 'day',\n",
       " 'month']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(df.columns)\n",
    "cols = [col for col in cols if df.dtypes[col] != 'object' and col not in ['version', 'datetime']]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[col for col in cols if col not in ['temperature']]].persist()\n",
    "y = df.temperature.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.36 s, sys: 189 ms, total: 1.55 s\n",
      "Wall time: 1min 56s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=1, missing=None, n_estimators=10,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBRegressor(n_estimators=10)\n",
    "%time xgb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.48 s, sys: 4.54 s, total: 11 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%time y_pred = xgb.predict(X).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = (((y.to_dask_array().compute()-y_pred)**2).mean())**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.851566034527197\n"
     ]
    }
   ],
   "source": [
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End the run\n",
    "\n",
    "Cluster will return to 0 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.close()\n",
    "run.cancel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
